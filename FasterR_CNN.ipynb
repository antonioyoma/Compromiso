{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNvxu2cORcFZUzvxHHWgHS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonioyoma/Compromiso/blob/master/FasterR_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ3V7epiQDeM",
        "outputId": "b56e39a1-dcef-4d86-89ae-15f72684aa66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.0\n",
        "!pip install torchvision==0.15.1\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install matplotlib==3.5.3\n",
        "!pip install git+https://github.com/facebookresearch/detectron2.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "293YR001UvNW",
        "outputId": "ed92a36d-5de5-41e0-f198-26730439eec3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=393212e6468b57e1e438e4c716f2fcf30673ceb41ef5b4240d478e1d0be35288\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n",
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision==0.15.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision==0.15.1) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision==0.15.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision==0.15.1) (17.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchvision==0.15.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchvision==0.15.1) (1.3.0)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "Successfully installed torchvision-0.15.1\n",
            "Collecting opencv-python==4.6.0.66\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.6.0.66) (1.23.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "Successfully installed opencv-python-4.6.0.66\n",
            "Collecting matplotlib==3.5.3\n",
            "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.3) (1.16.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-a46_haw7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-a46_haw7\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit a0e22dbfa791e6235e4f196d5ce25e754d02be31\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.5.3)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.14.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m922.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black (from detectron2==0.6)\n",
            "  Downloading black-23.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (3.9.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7.4->black->detectron2==0.6) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7.4->black->detectron2==0.6) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7.4->black->detectron2==0.6) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7.4->black->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7.4->black->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7.4->black->detectron2==0.6) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6079412 sha256=c92c971c8a59ef510c488dad47b6bc5cf737cfd176b1d27c40c0fe3edd1f41e4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pu0n3hzx/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=9be3ca79357b1eddf84621dd7661ad5abe44b36412883c7c178ab2c1efe9f0a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b43078af0455c88882cafa90b80f63e57f4ea6a8b762176d2d5b5c30b19705fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-23.12.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Colab Notebooks/Faster R-CNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUmnqHP8VPS8",
        "outputId": "8f590051-d65f-4311-836c-a3f42965df2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/Faster R-CNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --device gpu --learning-rate 0.00001 --iterations 6000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGOrrPo3aPuH",
        "outputId": "845f265d-f1d7-4a60-ef7a-0b9dbf2ffdbb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading config /usr/local/lib/python3.10/dist-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
            "\u001b[32m[12/12 18:52:36 d2.engine.defaults]: \u001b[0mModel:\n",
            "RetinaNet(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelP6P7(\n",
            "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    )\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): RetinaNetHead(\n",
            "    (cls_subnet): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (5): ReLU()\n",
            "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU()\n",
            "    )\n",
            "    (bbox_subnet): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (5): ReLU()\n",
            "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU()\n",
            "    )\n",
            "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (anchor_generator): DefaultAnchorGenerator(\n",
            "    (cell_anchors): BufferList()\n",
            "  )\n",
            ")\n",
            "[ WARN:0@6.970] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-316_jpg.rf.7036bcc1d01003d5cdec7ffa649b68f1 (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-316_jpg.rf.7036bcc1d01003d5cdec7ffa649b68f1 (1).jpg. Unable to load image.\n",
            "[ WARN:0@6.970] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-311_jpg.rf.7b3fd3240bb48a5ef77bc91d7933faf5 (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-311_jpg.rf.7b3fd3240bb48a5ef77bc91d7933faf5 (1).jpg. Unable to load image.\n",
            "[ WARN:0@6.970] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-30_jpg.rf.dd22b0f8d1e3870cc282deb58a3ba0d9 (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-30_jpg.rf.dd22b0f8d1e3870cc282deb58a3ba0d9 (1).jpg. Unable to load image.\n",
            "[ WARN:0@7.236] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-313_jpg.rf.375a5b2c36da95dedf424660730e8220 (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-313_jpg.rf.375a5b2c36da95dedf424660730e8220 (1).jpg. Unable to load image.\n",
            "[ WARN:0@7.828] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-309_jpg.rf.d823617bfa4fecc3c12d4a1b91f3c94d (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-309_jpg.rf.d823617bfa4fecc3c12d4a1b91f3c94d (1).jpg. Unable to load image.\n",
            "[ WARN:0@8.062] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-314_jpg.rf.8a137e8f5ffa9d03ad34f2027111e5f8 (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-314_jpg.rf.8a137e8f5ffa9d03ad34f2027111e5f8 (1).jpg. Unable to load image.\n",
            "[ WARN:0@8.977] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-312_jpg.rf.9f48bd79160e5353d64557cccf2b745b (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-312_jpg.rf.9f48bd79160e5353d64557cccf2b745b (1).jpg. Unable to load image.\n",
            "[ WARN:0@10.182] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-318_jpg.rf.040a4e2b78d3c8d452897db779bbcf41 (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-318_jpg.rf.040a4e2b78d3c8d452897db779bbcf41 (1).jpg. Unable to load image.\n",
            "[ WARN:0@11.433] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-315_jpg.rf.f30a34eab472b15ba9e3a79405507953 (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-315_jpg.rf.f30a34eab472b15ba9e3a79405507953 (1).jpg. Unable to load image.\n",
            "[ WARN:0@11.434] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/train/imgs/pagi_16112021_mp4-317_jpg.rf.0ca61369727244e6beae9150cf94d2fd (1).jpg'): can't open/read file: check file path/integrity\n",
            "Skipping file: ./data/train/imgs/pagi_16112021_mp4-317_jpg.rf.0ca61369727244e6beae9150cf94d2fd (1).jpg. Unable to load image.\n",
            "\u001b[32m[12/12 19:02:49 d2.data.build]: \u001b[0mRemoved 98 images with no usable annotations. 2536 images left.\n",
            "\u001b[32m[12/12 19:02:49 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|     ca     | 19083        |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[12/12 19:02:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[12/12 19:02:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[12/12 19:02:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[12/12 19:02:49 d2.data.common]: \u001b[0mSerializing 2536 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/12 19:02:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.07 MiB\n",
            "\u001b[32m[12/12 19:02:49 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
            "\u001b[32m[12/12 19:07:38 d2.data.build]: \u001b[0mRemoved 39 images with no usable annotations. 927 images left.\n",
            "\u001b[32m[12/12 19:07:38 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|     ca     | 8537         |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[12/12 19:07:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[12/12 19:07:38 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[12/12 19:07:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[12/12 19:07:38 d2.data.common]: \u001b[0mSerializing 927 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/12 19:07:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n",
            "\u001b[32m[12/12 19:07:38 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
            "\u001b[32m[12/12 19:07:38 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl ...\n",
            "model_final_971ab9.pkl: 228MB [00:06, 35.0MB/s]               \n",
            "The checkpoint state_dict contains keys that are not used by the model:\n",
            "  \u001b[35mpixel_mean\u001b[0m\n",
            "  \u001b[35mpixel_std\u001b[0m\n",
            "\u001b[32m[12/12 19:07:44 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m[12/12 19:08:25 d2.utils.events]: \u001b[0m eta: 1:40:48  iter: 19  total_loss: 1.933  loss_cls: 1.597  loss_box_reg: 0.3584  total_val_loss: 2.376  val_loss_cls: 1.921  val_loss_box_reg: 0.4696    time: 1.0706  last_time: 0.9548  data_time: 0.0405  last_data_time: 0.0308   lr: 1.9981e-07  max_mem: 5545M\n",
            "2023-12-12 19:08:26.070805: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-12 19:08:26.070883: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-12 19:08:26.070926: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-12 19:08:28.193200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m[12/12 19:09:01 d2.utils.events]: \u001b[0m eta: 1:47:41  iter: 39  total_loss: 1.65  loss_cls: 1.344  loss_box_reg: 0.2858  total_val_loss: 1.91  val_loss_cls: 1.519  val_loss_box_reg: 0.342    time: 1.1023  last_time: 1.1325  data_time: 0.0300  last_data_time: 0.0337   lr: 3.9961e-07  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:09:30 d2.utils.events]: \u001b[0m eta: 1:46:08  iter: 59  total_loss: 1.795  loss_cls: 1.46  loss_box_reg: 0.3052  total_val_loss: 1.793  val_loss_cls: 1.473  val_loss_box_reg: 0.3497    time: 1.0695  last_time: 0.8240  data_time: 0.0260  last_data_time: 0.0106   lr: 5.9941e-07  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:10:00 d2.utils.events]: \u001b[0m eta: 1:45:47  iter: 79  total_loss: 1.343  loss_cls: 1.123  loss_box_reg: 0.2397  total_val_loss: 1.942  val_loss_cls: 1.589  val_loss_box_reg: 0.3591    time: 1.0586  last_time: 0.9574  data_time: 0.0270  last_data_time: 0.0334   lr: 7.9921e-07  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:10:30 d2.utils.events]: \u001b[0m eta: 1:47:02  iter: 99  total_loss: 1.647  loss_cls: 1.377  loss_box_reg: 0.3248  total_val_loss: 1.651  val_loss_cls: 1.355  val_loss_box_reg: 0.3398    time: 1.0571  last_time: 1.1082  data_time: 0.0363  last_data_time: 0.0137   lr: 9.9901e-07  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:11:00 d2.utils.events]: \u001b[0m eta: 1:46:54  iter: 119  total_loss: 1.58  loss_cls: 1.262  loss_box_reg: 0.3149  total_val_loss: 1.555  val_loss_cls: 1.278  val_loss_box_reg: 0.3062    time: 1.0533  last_time: 1.1408  data_time: 0.0305  last_data_time: 0.0549   lr: 1.1988e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:11:30 d2.utils.events]: \u001b[0m eta: 1:46:27  iter: 139  total_loss: 1.47  loss_cls: 1.167  loss_box_reg: 0.3162  total_val_loss: 1.608  val_loss_cls: 1.272  val_loss_box_reg: 0.3095    time: 1.0498  last_time: 0.9514  data_time: 0.0243  last_data_time: 0.0224   lr: 1.3986e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:11:59 d2.utils.events]: \u001b[0m eta: 1:46:10  iter: 159  total_loss: 1.405  loss_cls: 1.123  loss_box_reg: 0.288  total_val_loss: 1.445  val_loss_cls: 1.133  val_loss_box_reg: 0.3143    time: 1.0493  last_time: 1.0884  data_time: 0.0380  last_data_time: 0.0119   lr: 1.5984e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:12:29 d2.utils.events]: \u001b[0m eta: 1:45:38  iter: 179  total_loss: 1.36  loss_cls: 1.08  loss_box_reg: 0.2947  total_val_loss: 1.439  val_loss_cls: 1.055  val_loss_box_reg: 0.3438    time: 1.0455  last_time: 0.9649  data_time: 0.0372  last_data_time: 0.0720   lr: 1.7982e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:12:58 d2.utils.events]: \u001b[0m eta: 1:45:21  iter: 199  total_loss: 1.063  loss_cls: 0.8615  loss_box_reg: 0.2176  total_val_loss: 1.504  val_loss_cls: 1.103  val_loss_box_reg: 0.3772    time: 1.0432  last_time: 1.1207  data_time: 0.0324  last_data_time: 0.0235   lr: 1.998e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:13:28 d2.utils.events]: \u001b[0m eta: 1:45:04  iter: 219  total_loss: 1.15  loss_cls: 0.8732  loss_box_reg: 0.2923  total_val_loss: 1.402  val_loss_cls: 1.056  val_loss_box_reg: 0.294    time: 1.0422  last_time: 0.8095  data_time: 0.0302  last_data_time: 0.0383   lr: 2.1978e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:13:57 d2.utils.events]: \u001b[0m eta: 1:44:43  iter: 239  total_loss: 1.079  loss_cls: 0.7551  loss_box_reg: 0.3017  total_val_loss: 1.317  val_loss_cls: 0.9096  val_loss_box_reg: 0.3849    time: 1.0413  last_time: 0.8964  data_time: 0.0210  last_data_time: 0.0105   lr: 2.3976e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:14:27 d2.utils.events]: \u001b[0m eta: 1:44:21  iter: 259  total_loss: 0.9519  loss_cls: 0.6439  loss_box_reg: 0.2992  total_val_loss: 1.037  val_loss_cls: 0.7604  val_loss_box_reg: 0.3049    time: 1.0389  last_time: 1.1465  data_time: 0.0384  last_data_time: 0.0600   lr: 2.5974e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:14:56 d2.utils.events]: \u001b[0m eta: 1:43:49  iter: 279  total_loss: 0.8169  loss_cls: 0.6064  loss_box_reg: 0.233  total_val_loss: 0.9993  val_loss_cls: 0.6855  val_loss_box_reg: 0.3334    time: 1.0364  last_time: 0.8358  data_time: 0.0374  last_data_time: 0.0209   lr: 2.7972e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:15:26 d2.utils.events]: \u001b[0m eta: 1:43:29  iter: 299  total_loss: 0.8422  loss_cls: 0.5703  loss_box_reg: 0.2694  total_val_loss: 0.9778  val_loss_cls: 0.6708  val_loss_box_reg: 0.3568    time: 1.0370  last_time: 1.1183  data_time: 0.0355  last_data_time: 0.0346   lr: 2.997e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:15:57 d2.utils.events]: \u001b[0m eta: 1:43:16  iter: 319  total_loss: 0.7891  loss_cls: 0.4922  loss_box_reg: 0.2931  total_val_loss: 0.9093  val_loss_cls: 0.6113  val_loss_box_reg: 0.3157    time: 1.0389  last_time: 1.0119  data_time: 0.0361  last_data_time: 0.0752   lr: 3.1968e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:16:27 d2.utils.events]: \u001b[0m eta: 1:43:00  iter: 339  total_loss: 0.6325  loss_cls: 0.3888  loss_box_reg: 0.2488  total_val_loss: 0.837  val_loss_cls: 0.4622  val_loss_box_reg: 0.3438    time: 1.0404  last_time: 0.8386  data_time: 0.0346  last_data_time: 0.0116   lr: 3.3966e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:16:56 d2.utils.events]: \u001b[0m eta: 1:42:39  iter: 359  total_loss: 0.6757  loss_cls: 0.4068  loss_box_reg: 0.2562  total_val_loss: 0.809  val_loss_cls: 0.454  val_loss_box_reg: 0.3562    time: 1.0405  last_time: 0.9685  data_time: 0.0316  last_data_time: 0.0329   lr: 3.5964e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:17:27 d2.utils.events]: \u001b[0m eta: 1:42:18  iter: 379  total_loss: 0.6477  loss_cls: 0.3651  loss_box_reg: 0.2677  total_val_loss: 0.7378  val_loss_cls: 0.4018  val_loss_box_reg: 0.3327    time: 1.0408  last_time: 0.9245  data_time: 0.0310  last_data_time: 0.0335   lr: 3.7962e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:17:57 d2.utils.events]: \u001b[0m eta: 1:41:58  iter: 399  total_loss: 0.5682  loss_cls: 0.3063  loss_box_reg: 0.2532  total_val_loss: 0.7034  val_loss_cls: 0.3636  val_loss_box_reg: 0.3373    time: 1.0405  last_time: 1.1450  data_time: 0.0322  last_data_time: 0.0565   lr: 3.996e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:18:26 d2.utils.events]: \u001b[0m eta: 1:41:36  iter: 419  total_loss: 0.5215  loss_cls: 0.2918  loss_box_reg: 0.228  total_val_loss: 0.7153  val_loss_cls: 0.3946  val_loss_box_reg: 0.3277    time: 1.0395  last_time: 0.9146  data_time: 0.0254  last_data_time: 0.0166   lr: 4.1958e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:18:55 d2.utils.events]: \u001b[0m eta: 1:41:11  iter: 439  total_loss: 0.6302  loss_cls: 0.3338  loss_box_reg: 0.2852  total_val_loss: 0.6513  val_loss_cls: 0.3208  val_loss_box_reg: 0.3337    time: 1.0381  last_time: 0.9296  data_time: 0.0320  last_data_time: 0.0349   lr: 4.3956e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:19:24 d2.utils.events]: \u001b[0m eta: 1:40:47  iter: 459  total_loss: 0.6048  loss_cls: 0.3161  loss_box_reg: 0.301  total_val_loss: 0.6427  val_loss_cls: 0.3249  val_loss_box_reg: 0.3238    time: 1.0365  last_time: 1.1237  data_time: 0.0299  last_data_time: 0.0418   lr: 4.5954e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:19:53 d2.utils.events]: \u001b[0m eta: 1:40:24  iter: 479  total_loss: 0.5577  loss_cls: 0.2843  loss_box_reg: 0.2485  total_val_loss: 0.5373  val_loss_cls: 0.2911  val_loss_box_reg: 0.2614    time: 1.0359  last_time: 1.0080  data_time: 0.0305  last_data_time: 0.0650   lr: 4.7952e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:20:26 d2.utils.events]: \u001b[0m eta: 1:40:05  iter: 499  total_loss: 0.4907  loss_cls: 0.26  loss_box_reg: 0.2439  total_val_loss: 0.6494  val_loss_cls: 0.3018  val_loss_box_reg: 0.3425    time: 1.0365  last_time: 0.9303  data_time: 0.0276  last_data_time: 0.0324   lr: 4.995e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:20:55 d2.utils.events]: \u001b[0m eta: 1:39:39  iter: 519  total_loss: 0.5335  loss_cls: 0.2698  loss_box_reg: 0.2623  total_val_loss: 0.6154  val_loss_cls: 0.2971  val_loss_box_reg: 0.3202    time: 1.0358  last_time: 0.9280  data_time: 0.0349  last_data_time: 0.0385   lr: 5.1948e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:21:25 d2.utils.events]: \u001b[0m eta: 1:39:17  iter: 539  total_loss: 0.5229  loss_cls: 0.2552  loss_box_reg: 0.2726  total_val_loss: 0.557  val_loss_cls: 0.2661  val_loss_box_reg: 0.3052    time: 1.0362  last_time: 1.1116  data_time: 0.0409  last_data_time: 0.0332   lr: 5.3946e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:21:55 d2.utils.events]: \u001b[0m eta: 1:39:00  iter: 559  total_loss: 0.4715  loss_cls: 0.2453  loss_box_reg: 0.2326  total_val_loss: 0.539  val_loss_cls: 0.2546  val_loss_box_reg: 0.28    time: 1.0371  last_time: 0.9522  data_time: 0.0361  last_data_time: 0.0553   lr: 5.5944e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:22:25 d2.utils.events]: \u001b[0m eta: 1:38:38  iter: 579  total_loss: 0.5252  loss_cls: 0.266  loss_box_reg: 0.2583  total_val_loss: 0.6017  val_loss_cls: 0.2697  val_loss_box_reg: 0.3233    time: 1.0368  last_time: 0.9061  data_time: 0.0312  last_data_time: 0.0124   lr: 5.7942e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:22:55 d2.utils.events]: \u001b[0m eta: 1:38:14  iter: 599  total_loss: 0.5436  loss_cls: 0.2894  loss_box_reg: 0.2406  total_val_loss: 0.5798  val_loss_cls: 0.2773  val_loss_box_reg: 0.3162    time: 1.0367  last_time: 0.9580  data_time: 0.0353  last_data_time: 0.0311   lr: 5.994e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:23:24 d2.utils.events]: \u001b[0m eta: 1:37:53  iter: 619  total_loss: 0.5418  loss_cls: 0.2473  loss_box_reg: 0.3032  total_val_loss: 0.5203  val_loss_cls: 0.2434  val_loss_box_reg: 0.2926    time: 1.0366  last_time: 1.1137  data_time: 0.0338  last_data_time: 0.0333   lr: 6.1938e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:23:54 d2.utils.events]: \u001b[0m eta: 1:37:33  iter: 639  total_loss: 0.5398  loss_cls: 0.2757  loss_box_reg: 0.2659  total_val_loss: 0.6569  val_loss_cls: 0.2868  val_loss_box_reg: 0.3499    time: 1.0369  last_time: 1.1338  data_time: 0.0259  last_data_time: 0.0410   lr: 6.3936e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:24:24 d2.utils.events]: \u001b[0m eta: 1:37:11  iter: 659  total_loss: 0.4567  loss_cls: 0.2433  loss_box_reg: 0.2184  total_val_loss: 0.519  val_loss_cls: 0.2417  val_loss_box_reg: 0.2886    time: 1.0369  last_time: 1.1078  data_time: 0.0311  last_data_time: 0.0232   lr: 6.5934e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:24:54 d2.utils.events]: \u001b[0m eta: 1:36:51  iter: 679  total_loss: 0.3835  loss_cls: 0.1802  loss_box_reg: 0.1991  total_val_loss: 0.5886  val_loss_cls: 0.2489  val_loss_box_reg: 0.3539    time: 1.0374  last_time: 1.1195  data_time: 0.0330  last_data_time: 0.0346   lr: 6.7932e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:25:23 d2.utils.events]: \u001b[0m eta: 1:36:28  iter: 699  total_loss: 0.4845  loss_cls: 0.2355  loss_box_reg: 0.2624  total_val_loss: 0.6103  val_loss_cls: 0.2836  val_loss_box_reg: 0.3239    time: 1.0376  last_time: 1.0934  data_time: 0.0360  last_data_time: 0.0103   lr: 6.993e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:25:53 d2.utils.events]: \u001b[0m eta: 1:36:05  iter: 719  total_loss: 0.4601  loss_cls: 0.2427  loss_box_reg: 0.2133  total_val_loss: 0.5956  val_loss_cls: 0.2606  val_loss_box_reg: 0.3408    time: 1.0368  last_time: 1.1131  data_time: 0.0294  last_data_time: 0.0110   lr: 7.1928e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:26:23 d2.utils.events]: \u001b[0m eta: 1:35:44  iter: 739  total_loss: 0.4975  loss_cls: 0.2457  loss_box_reg: 0.2659  total_val_loss: 0.5725  val_loss_cls: 0.2537  val_loss_box_reg: 0.3062    time: 1.0370  last_time: 0.9670  data_time: 0.0302  last_data_time: 0.0300   lr: 7.3926e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:26:52 d2.utils.events]: \u001b[0m eta: 1:35:22  iter: 759  total_loss: 0.4159  loss_cls: 0.193  loss_box_reg: 0.2237  total_val_loss: 0.5119  val_loss_cls: 0.2414  val_loss_box_reg: 0.2784    time: 1.0368  last_time: 0.8023  data_time: 0.0352  last_data_time: 0.0308   lr: 7.5924e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:27:21 d2.utils.events]: \u001b[0m eta: 1:34:58  iter: 779  total_loss: 0.4759  loss_cls: 0.2148  loss_box_reg: 0.2611  total_val_loss: 0.6361  val_loss_cls: 0.2475  val_loss_box_reg: 0.3472    time: 1.0358  last_time: 0.9882  data_time: 0.0379  last_data_time: 0.0537   lr: 7.7922e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:27:50 d2.utils.events]: \u001b[0m eta: 1:34:33  iter: 799  total_loss: 0.4533  loss_cls: 0.2106  loss_box_reg: 0.2369  total_val_loss: 0.5868  val_loss_cls: 0.2589  val_loss_box_reg: 0.3458    time: 1.0353  last_time: 0.9796  data_time: 0.0326  last_data_time: 0.0607   lr: 7.992e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:28:21 d2.utils.events]: \u001b[0m eta: 1:34:14  iter: 819  total_loss: 0.4814  loss_cls: 0.2301  loss_box_reg: 0.2504  total_val_loss: 0.5265  val_loss_cls: 0.2397  val_loss_box_reg: 0.2868    time: 1.0360  last_time: 0.9203  data_time: 0.0313  last_data_time: 0.0337   lr: 8.1918e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:28:50 d2.utils.events]: \u001b[0m eta: 1:33:49  iter: 839  total_loss: 0.382  loss_cls: 0.2016  loss_box_reg: 0.2084  total_val_loss: 0.5806  val_loss_cls: 0.2579  val_loss_box_reg: 0.3077    time: 1.0353  last_time: 0.9673  data_time: 0.0384  last_data_time: 0.0374   lr: 8.3916e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:29:21 d2.utils.events]: \u001b[0m eta: 1:33:33  iter: 859  total_loss: 0.4794  loss_cls: 0.2192  loss_box_reg: 0.2537  total_val_loss: 0.5724  val_loss_cls: 0.2449  val_loss_box_reg: 0.3125    time: 1.0363  last_time: 0.9548  data_time: 0.0383  last_data_time: 0.0603   lr: 8.5914e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:29:51 d2.utils.events]: \u001b[0m eta: 1:33:11  iter: 879  total_loss: 0.4132  loss_cls: 0.1912  loss_box_reg: 0.2248  total_val_loss: 0.5224  val_loss_cls: 0.2243  val_loss_box_reg: 0.3002    time: 1.0369  last_time: 0.9596  data_time: 0.0358  last_data_time: 0.0485   lr: 8.7912e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:30:20 d2.utils.events]: \u001b[0m eta: 1:32:49  iter: 899  total_loss: 0.4814  loss_cls: 0.2225  loss_box_reg: 0.2648  total_val_loss: 0.5626  val_loss_cls: 0.2485  val_loss_box_reg: 0.323    time: 1.0359  last_time: 1.1191  data_time: 0.0318  last_data_time: 0.0339   lr: 8.991e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:30:50 d2.utils.events]: \u001b[0m eta: 1:32:26  iter: 919  total_loss: 0.4261  loss_cls: 0.2072  loss_box_reg: 0.2467  total_val_loss: 0.5491  val_loss_cls: 0.2296  val_loss_box_reg: 0.3195    time: 1.0360  last_time: 0.9555  data_time: 0.0423  last_data_time: 0.0226   lr: 9.1908e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:31:19 d2.utils.events]: \u001b[0m eta: 1:32:02  iter: 939  total_loss: 0.5302  loss_cls: 0.243  loss_box_reg: 0.2866  total_val_loss: 0.4828  val_loss_cls: 0.2012  val_loss_box_reg: 0.272    time: 1.0354  last_time: 0.9553  data_time: 0.0275  last_data_time: 0.0106   lr: 9.3906e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:31:50 d2.utils.events]: \u001b[0m eta: 1:31:43  iter: 959  total_loss: 0.5042  loss_cls: 0.2202  loss_box_reg: 0.2732  total_val_loss: 0.5758  val_loss_cls: 0.2387  val_loss_box_reg: 0.3272    time: 1.0363  last_time: 1.1380  data_time: 0.0391  last_data_time: 0.0461   lr: 9.5904e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:32:20 d2.utils.events]: \u001b[0m eta: 1:31:23  iter: 979  total_loss: 0.3761  loss_cls: 0.169  loss_box_reg: 0.2081  total_val_loss: 0.5327  val_loss_cls: 0.2342  val_loss_box_reg: 0.3055    time: 1.0370  last_time: 1.1133  data_time: 0.0299  last_data_time: 0.0348   lr: 9.7902e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:32:52 d2.utils.events]: \u001b[0m eta: 1:31:02  iter: 999  total_loss: 0.4633  loss_cls: 0.1975  loss_box_reg: 0.2629  total_val_loss: 0.5258  val_loss_cls: 0.2305  val_loss_box_reg: 0.3119    time: 1.0373  last_time: 1.1217  data_time: 0.0291  last_data_time: 0.0366   lr: 9.99e-06  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:33:22 d2.utils.events]: \u001b[0m eta: 1:30:41  iter: 1019  total_loss: 0.4505  loss_cls: 0.199  loss_box_reg: 0.2198  total_val_loss: 0.492  val_loss_cls: 0.2206  val_loss_box_reg: 0.2877    time: 1.0373  last_time: 1.0948  data_time: 0.0399  last_data_time: 0.0160   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:33:51 d2.utils.events]: \u001b[0m eta: 1:30:17  iter: 1039  total_loss: 0.4086  loss_cls: 0.1942  loss_box_reg: 0.2188  total_val_loss: 0.512  val_loss_cls: 0.2132  val_loss_box_reg: 0.2988    time: 1.0368  last_time: 0.9102  data_time: 0.0367  last_data_time: 0.0098   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:34:20 d2.utils.events]: \u001b[0m eta: 1:29:54  iter: 1059  total_loss: 0.5069  loss_cls: 0.2191  loss_box_reg: 0.3009  total_val_loss: 0.5357  val_loss_cls: 0.2191  val_loss_box_reg: 0.3077    time: 1.0358  last_time: 1.1099  data_time: 0.0314  last_data_time: 0.0309   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:34:50 d2.utils.events]: \u001b[0m eta: 1:29:34  iter: 1079  total_loss: 0.4373  loss_cls: 0.1945  loss_box_reg: 0.2288  total_val_loss: 0.4566  val_loss_cls: 0.2051  val_loss_box_reg: 0.2614    time: 1.0365  last_time: 0.9420  data_time: 0.0347  last_data_time: 0.0133   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:35:21 d2.utils.events]: \u001b[0m eta: 1:29:13  iter: 1099  total_loss: 0.43  loss_cls: 0.1667  loss_box_reg: 0.2582  total_val_loss: 0.5424  val_loss_cls: 0.2325  val_loss_box_reg: 0.3172    time: 1.0369  last_time: 1.1146  data_time: 0.0291  last_data_time: 0.0324   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:35:51 d2.utils.events]: \u001b[0m eta: 1:28:52  iter: 1119  total_loss: 0.4688  loss_cls: 0.1955  loss_box_reg: 0.2673  total_val_loss: 0.5301  val_loss_cls: 0.1998  val_loss_box_reg: 0.3164    time: 1.0373  last_time: 0.9374  data_time: 0.0356  last_data_time: 0.0100   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:36:20 d2.utils.events]: \u001b[0m eta: 1:28:30  iter: 1139  total_loss: 0.4928  loss_cls: 0.207  loss_box_reg: 0.2749  total_val_loss: 0.4711  val_loss_cls: 0.1939  val_loss_box_reg: 0.2772    time: 1.0371  last_time: 0.9234  data_time: 0.0302  last_data_time: 0.0347   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:36:51 d2.utils.events]: \u001b[0m eta: 1:28:09  iter: 1159  total_loss: 0.4639  loss_cls: 0.1853  loss_box_reg: 0.2711  total_val_loss: 0.4948  val_loss_cls: 0.2082  val_loss_box_reg: 0.283    time: 1.0377  last_time: 1.0939  data_time: 0.0292  last_data_time: 0.0128   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:37:21 d2.utils.events]: \u001b[0m eta: 1:27:49  iter: 1179  total_loss: 0.4566  loss_cls: 0.1872  loss_box_reg: 0.2586  total_val_loss: 0.4835  val_loss_cls: 0.2025  val_loss_box_reg: 0.2735    time: 1.0380  last_time: 0.9656  data_time: 0.0438  last_data_time: 0.0321   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:37:50 d2.utils.events]: \u001b[0m eta: 1:27:27  iter: 1199  total_loss: 0.4351  loss_cls: 0.1894  loss_box_reg: 0.2482  total_val_loss: 0.562  val_loss_cls: 0.2135  val_loss_box_reg: 0.3429    time: 1.0379  last_time: 1.1186  data_time: 0.0282  last_data_time: 0.0206   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:38:20 d2.utils.events]: \u001b[0m eta: 1:27:05  iter: 1219  total_loss: 0.47  loss_cls: 0.1859  loss_box_reg: 0.2701  total_val_loss: 0.4953  val_loss_cls: 0.2027  val_loss_box_reg: 0.2879    time: 1.0378  last_time: 0.9382  data_time: 0.0275  last_data_time: 0.0112   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:38:50 d2.utils.events]: \u001b[0m eta: 1:26:44  iter: 1239  total_loss: 0.4848  loss_cls: 0.2102  loss_box_reg: 0.2705  total_val_loss: 0.5768  val_loss_cls: 0.256  val_loss_box_reg: 0.3303    time: 1.0381  last_time: 1.0984  data_time: 0.0339  last_data_time: 0.0163   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:39:20 d2.utils.events]: \u001b[0m eta: 1:26:22  iter: 1259  total_loss: 0.3998  loss_cls: 0.1879  loss_box_reg: 0.2065  total_val_loss: 0.4901  val_loss_cls: 0.1977  val_loss_box_reg: 0.2874    time: 1.0380  last_time: 0.9738  data_time: 0.0356  last_data_time: 0.0392   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:39:49 d2.utils.events]: \u001b[0m eta: 1:26:01  iter: 1279  total_loss: 0.3939  loss_cls: 0.1725  loss_box_reg: 0.2235  total_val_loss: 0.4771  val_loss_cls: 0.1856  val_loss_box_reg: 0.2697    time: 1.0379  last_time: 1.1550  data_time: 0.0335  last_data_time: 0.0601   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:40:19 d2.utils.events]: \u001b[0m eta: 1:25:39  iter: 1299  total_loss: 0.4544  loss_cls: 0.2027  loss_box_reg: 0.2495  total_val_loss: 0.5149  val_loss_cls: 0.2232  val_loss_box_reg: 0.3117    time: 1.0378  last_time: 0.9597  data_time: 0.0350  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:40:49 d2.utils.events]: \u001b[0m eta: 1:25:16  iter: 1319  total_loss: 0.4755  loss_cls: 0.2053  loss_box_reg: 0.2804  total_val_loss: 0.4087  val_loss_cls: 0.1703  val_loss_box_reg: 0.2312    time: 1.0378  last_time: 1.1128  data_time: 0.0341  last_data_time: 0.0341   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:41:19 d2.utils.events]: \u001b[0m eta: 1:24:54  iter: 1339  total_loss: 0.4138  loss_cls: 0.1668  loss_box_reg: 0.2453  total_val_loss: 0.6274  val_loss_cls: 0.2565  val_loss_box_reg: 0.3547    time: 1.0382  last_time: 1.1453  data_time: 0.0312  last_data_time: 0.0598   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:41:49 d2.utils.events]: \u001b[0m eta: 1:24:31  iter: 1359  total_loss: 0.4225  loss_cls: 0.1767  loss_box_reg: 0.234  total_val_loss: 0.4515  val_loss_cls: 0.1865  val_loss_box_reg: 0.2618    time: 1.0381  last_time: 1.0138  data_time: 0.0327  last_data_time: 0.0624   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:42:19 d2.utils.events]: \u001b[0m eta: 1:24:09  iter: 1379  total_loss: 0.4125  loss_cls: 0.1884  loss_box_reg: 0.2325  total_val_loss: 0.5174  val_loss_cls: 0.2135  val_loss_box_reg: 0.3153    time: 1.0378  last_time: 0.8396  data_time: 0.0279  last_data_time: 0.0127   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:42:49 d2.utils.events]: \u001b[0m eta: 1:23:48  iter: 1399  total_loss: 0.3619  loss_cls: 0.1487  loss_box_reg: 0.1913  total_val_loss: 0.5581  val_loss_cls: 0.2228  val_loss_box_reg: 0.3353    time: 1.0382  last_time: 0.9482  data_time: 0.0270  last_data_time: 0.0217   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:43:19 d2.utils.events]: \u001b[0m eta: 1:23:25  iter: 1419  total_loss: 0.4123  loss_cls: 0.1886  loss_box_reg: 0.2196  total_val_loss: 0.5162  val_loss_cls: 0.2058  val_loss_box_reg: 0.3066    time: 1.0380  last_time: 0.9496  data_time: 0.0356  last_data_time: 0.0108   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:43:48 d2.utils.events]: \u001b[0m eta: 1:23:03  iter: 1439  total_loss: 0.4423  loss_cls: 0.1811  loss_box_reg: 0.2505  total_val_loss: 0.4541  val_loss_cls: 0.1776  val_loss_box_reg: 0.28    time: 1.0381  last_time: 0.9865  data_time: 0.0297  last_data_time: 0.0577   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:44:17 d2.utils.events]: \u001b[0m eta: 1:22:41  iter: 1459  total_loss: 0.4225  loss_cls: 0.171  loss_box_reg: 0.2515  total_val_loss: 0.543  val_loss_cls: 0.2172  val_loss_box_reg: 0.3202    time: 1.0375  last_time: 1.1192  data_time: 0.0342  last_data_time: 0.0322   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:44:48 d2.utils.events]: \u001b[0m eta: 1:22:20  iter: 1479  total_loss: 0.4098  loss_cls: 0.1902  loss_box_reg: 0.2365  total_val_loss: 0.4834  val_loss_cls: 0.1943  val_loss_box_reg: 0.2993    time: 1.0377  last_time: 0.9600  data_time: 0.0276  last_data_time: 0.0310   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:45:20 d2.utils.events]: \u001b[0m eta: 1:21:58  iter: 1499  total_loss: 0.4016  loss_cls: 0.1869  loss_box_reg: 0.235  total_val_loss: 0.4827  val_loss_cls: 0.1878  val_loss_box_reg: 0.2813    time: 1.0380  last_time: 0.9602  data_time: 0.0338  last_data_time: 0.0529   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:45:50 d2.utils.events]: \u001b[0m eta: 1:21:37  iter: 1519  total_loss: 0.3446  loss_cls: 0.1688  loss_box_reg: 0.1856  total_val_loss: 0.4482  val_loss_cls: 0.1784  val_loss_box_reg: 0.2696    time: 1.0379  last_time: 1.1470  data_time: 0.0298  last_data_time: 0.0308   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:46:20 d2.utils.events]: \u001b[0m eta: 1:21:16  iter: 1539  total_loss: 0.4447  loss_cls: 0.1882  loss_box_reg: 0.2565  total_val_loss: 0.5799  val_loss_cls: 0.2242  val_loss_box_reg: 0.3289    time: 1.0381  last_time: 1.1256  data_time: 0.0329  last_data_time: 0.0446   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:46:50 d2.utils.events]: \u001b[0m eta: 1:20:53  iter: 1559  total_loss: 0.3989  loss_cls: 0.1662  loss_box_reg: 0.22  total_val_loss: 0.4975  val_loss_cls: 0.1959  val_loss_box_reg: 0.2932    time: 1.0383  last_time: 0.9658  data_time: 0.0357  last_data_time: 0.0376   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:47:20 d2.utils.events]: \u001b[0m eta: 1:20:31  iter: 1579  total_loss: 0.4256  loss_cls: 0.1925  loss_box_reg: 0.2237  total_val_loss: 0.4547  val_loss_cls: 0.1942  val_loss_box_reg: 0.2698    time: 1.0384  last_time: 1.0986  data_time: 0.0407  last_data_time: 0.0110   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:47:48 d2.utils.events]: \u001b[0m eta: 1:20:08  iter: 1599  total_loss: 0.3658  loss_cls: 0.1821  loss_box_reg: 0.2101  total_val_loss: 0.4964  val_loss_cls: 0.2006  val_loss_box_reg: 0.2897    time: 1.0380  last_time: 1.1611  data_time: 0.0298  last_data_time: 0.0462   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:48:19 d2.utils.events]: \u001b[0m eta: 1:19:48  iter: 1619  total_loss: 0.4052  loss_cls: 0.1784  loss_box_reg: 0.2364  total_val_loss: 0.4756  val_loss_cls: 0.2051  val_loss_box_reg: 0.2901    time: 1.0384  last_time: 1.1227  data_time: 0.0351  last_data_time: 0.0323   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:48:49 d2.utils.events]: \u001b[0m eta: 1:19:26  iter: 1639  total_loss: 0.3933  loss_cls: 0.1731  loss_box_reg: 0.2194  total_val_loss: 0.5225  val_loss_cls: 0.2246  val_loss_box_reg: 0.3104    time: 1.0386  last_time: 1.1175  data_time: 0.0483  last_data_time: 0.0335   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:49:20 d2.utils.events]: \u001b[0m eta: 1:19:05  iter: 1659  total_loss: 0.429  loss_cls: 0.1681  loss_box_reg: 0.2627  total_val_loss: 0.4512  val_loss_cls: 0.1902  val_loss_box_reg: 0.266    time: 1.0390  last_time: 0.9833  data_time: 0.0416  last_data_time: 0.0531   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:49:49 d2.utils.events]: \u001b[0m eta: 1:18:42  iter: 1679  total_loss: 0.4532  loss_cls: 0.19  loss_box_reg: 0.2565  total_val_loss: 0.4493  val_loss_cls: 0.1732  val_loss_box_reg: 0.28    time: 1.0390  last_time: 0.9636  data_time: 0.0273  last_data_time: 0.0103   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:50:19 d2.utils.events]: \u001b[0m eta: 1:18:21  iter: 1699  total_loss: 0.4412  loss_cls: 0.1789  loss_box_reg: 0.2398  total_val_loss: 0.4876  val_loss_cls: 0.1895  val_loss_box_reg: 0.2994    time: 1.0390  last_time: 1.1148  data_time: 0.0325  last_data_time: 0.0294   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:50:49 d2.utils.events]: \u001b[0m eta: 1:17:59  iter: 1719  total_loss: 0.349  loss_cls: 0.1527  loss_box_reg: 0.1963  total_val_loss: 0.5222  val_loss_cls: 0.2143  val_loss_box_reg: 0.2991    time: 1.0388  last_time: 1.1187  data_time: 0.0380  last_data_time: 0.0340   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:51:19 d2.utils.events]: \u001b[0m eta: 1:17:35  iter: 1739  total_loss: 0.3734  loss_cls: 0.1648  loss_box_reg: 0.2098  total_val_loss: 0.5054  val_loss_cls: 0.1982  val_loss_box_reg: 0.2919    time: 1.0386  last_time: 0.9793  data_time: 0.0390  last_data_time: 0.0317   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:51:48 d2.utils.events]: \u001b[0m eta: 1:17:13  iter: 1759  total_loss: 0.3986  loss_cls: 0.1848  loss_box_reg: 0.2158  total_val_loss: 0.5409  val_loss_cls: 0.208  val_loss_box_reg: 0.3145    time: 1.0386  last_time: 1.1291  data_time: 0.0353  last_data_time: 0.0097   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:52:18 d2.utils.events]: \u001b[0m eta: 1:16:54  iter: 1779  total_loss: 0.4552  loss_cls: 0.1969  loss_box_reg: 0.2411  total_val_loss: 0.4957  val_loss_cls: 0.186  val_loss_box_reg: 0.2951    time: 1.0385  last_time: 0.9451  data_time: 0.0317  last_data_time: 0.0114   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:52:49 d2.utils.events]: \u001b[0m eta: 1:16:34  iter: 1799  total_loss: 0.3147  loss_cls: 0.1404  loss_box_reg: 0.1713  total_val_loss: 0.6071  val_loss_cls: 0.2482  val_loss_box_reg: 0.3532    time: 1.0388  last_time: 0.9660  data_time: 0.0305  last_data_time: 0.0314   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:53:19 d2.utils.events]: \u001b[0m eta: 1:16:12  iter: 1819  total_loss: 0.438  loss_cls: 0.1782  loss_box_reg: 0.253  total_val_loss: 0.4072  val_loss_cls: 0.1602  val_loss_box_reg: 0.2556    time: 1.0390  last_time: 0.9980  data_time: 0.0369  last_data_time: 0.0343   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:53:50 d2.utils.events]: \u001b[0m eta: 1:15:55  iter: 1839  total_loss: 0.4136  loss_cls: 0.1668  loss_box_reg: 0.2483  total_val_loss: 0.4455  val_loss_cls: 0.198  val_loss_box_reg: 0.2513    time: 1.0392  last_time: 1.1091  data_time: 0.0312  last_data_time: 0.0092   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:54:19 d2.utils.events]: \u001b[0m eta: 1:15:27  iter: 1859  total_loss: 0.3926  loss_cls: 0.1731  loss_box_reg: 0.208  total_val_loss: 0.5146  val_loss_cls: 0.1901  val_loss_box_reg: 0.3218    time: 1.0388  last_time: 1.1191  data_time: 0.0377  last_data_time: 0.0337   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:54:48 d2.utils.events]: \u001b[0m eta: 1:15:02  iter: 1879  total_loss: 0.4462  loss_cls: 0.1832  loss_box_reg: 0.2618  total_val_loss: 0.4813  val_loss_cls: 0.1986  val_loss_box_reg: 0.2879    time: 1.0382  last_time: 0.9436  data_time: 0.0327  last_data_time: 0.0099   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:55:17 d2.utils.events]: \u001b[0m eta: 1:14:40  iter: 1899  total_loss: 0.4  loss_cls: 0.1702  loss_box_reg: 0.2294  total_val_loss: 0.4765  val_loss_cls: 0.1879  val_loss_box_reg: 0.2816    time: 1.0381  last_time: 1.1669  data_time: 0.0326  last_data_time: 0.0630   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:55:47 d2.utils.events]: \u001b[0m eta: 1:14:18  iter: 1919  total_loss: 0.5188  loss_cls: 0.1999  loss_box_reg: 0.3006  total_val_loss: 0.568  val_loss_cls: 0.2176  val_loss_box_reg: 0.3441    time: 1.0379  last_time: 0.9296  data_time: 0.0289  last_data_time: 0.0336   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:56:16 d2.utils.events]: \u001b[0m eta: 1:13:56  iter: 1939  total_loss: 0.3469  loss_cls: 0.1439  loss_box_reg: 0.2003  total_val_loss: 0.4643  val_loss_cls: 0.1949  val_loss_box_reg: 0.2786    time: 1.0377  last_time: 1.1179  data_time: 0.0385  last_data_time: 0.0364   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:56:46 d2.utils.events]: \u001b[0m eta: 1:13:33  iter: 1959  total_loss: 0.4181  loss_cls: 0.1593  loss_box_reg: 0.2464  total_val_loss: 0.5148  val_loss_cls: 0.2023  val_loss_box_reg: 0.3029    time: 1.0377  last_time: 0.8965  data_time: 0.0369  last_data_time: 0.0608   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:57:16 d2.utils.events]: \u001b[0m eta: 1:13:10  iter: 1979  total_loss: 0.3799  loss_cls: 0.1594  loss_box_reg: 0.2213  total_val_loss: 0.466  val_loss_cls: 0.173  val_loss_box_reg: 0.2934    time: 1.0376  last_time: 1.1680  data_time: 0.0329  last_data_time: 0.0682   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:57:48 d2.utils.events]: \u001b[0m eta: 1:12:47  iter: 1999  total_loss: 0.3841  loss_cls: 0.1614  loss_box_reg: 0.217  total_val_loss: 0.5162  val_loss_cls: 0.2108  val_loss_box_reg: 0.3162    time: 1.0377  last_time: 1.0966  data_time: 0.0366  last_data_time: 0.0096   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:58:18 d2.utils.events]: \u001b[0m eta: 1:12:25  iter: 2019  total_loss: 0.4517  loss_cls: 0.1841  loss_box_reg: 0.2685  total_val_loss: 0.4663  val_loss_cls: 0.1776  val_loss_box_reg: 0.2827    time: 1.0379  last_time: 0.9684  data_time: 0.0339  last_data_time: 0.0369   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:58:48 d2.utils.events]: \u001b[0m eta: 1:12:06  iter: 2039  total_loss: 0.4222  loss_cls: 0.195  loss_box_reg: 0.2369  total_val_loss: 0.4537  val_loss_cls: 0.1776  val_loss_box_reg: 0.2724    time: 1.0379  last_time: 0.8658  data_time: 0.0321  last_data_time: 0.0350   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:59:18 d2.utils.events]: \u001b[0m eta: 1:11:45  iter: 2059  total_loss: 0.4217  loss_cls: 0.1638  loss_box_reg: 0.2609  total_val_loss: 0.4801  val_loss_cls: 0.1802  val_loss_box_reg: 0.2909    time: 1.0378  last_time: 1.1236  data_time: 0.0307  last_data_time: 0.0154   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 19:59:48 d2.utils.events]: \u001b[0m eta: 1:11:22  iter: 2079  total_loss: 0.3463  loss_cls: 0.1649  loss_box_reg: 0.1932  total_val_loss: 0.4289  val_loss_cls: 0.1782  val_loss_box_reg: 0.2571    time: 1.0377  last_time: 1.0024  data_time: 0.0294  last_data_time: 0.0472   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:00:18 d2.utils.events]: \u001b[0m eta: 1:11:00  iter: 2099  total_loss: 0.357  loss_cls: 0.1551  loss_box_reg: 0.2094  total_val_loss: 0.4939  val_loss_cls: 0.1901  val_loss_box_reg: 0.2931    time: 1.0381  last_time: 1.1406  data_time: 0.0424  last_data_time: 0.0431   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:00:50 d2.utils.events]: \u001b[0m eta: 1:10:38  iter: 2119  total_loss: 0.4006  loss_cls: 0.1791  loss_box_reg: 0.2043  total_val_loss: 0.4528  val_loss_cls: 0.175  val_loss_box_reg: 0.2821    time: 1.0386  last_time: 0.9683  data_time: 0.0499  last_data_time: 0.0426   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:01:19 d2.utils.events]: \u001b[0m eta: 1:10:16  iter: 2139  total_loss: 0.4394  loss_cls: 0.1747  loss_box_reg: 0.2689  total_val_loss: 0.4152  val_loss_cls: 0.1662  val_loss_box_reg: 0.263    time: 1.0385  last_time: 0.9656  data_time: 0.0291  last_data_time: 0.0130   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:01:49 d2.utils.events]: \u001b[0m eta: 1:09:52  iter: 2159  total_loss: 0.3125  loss_cls: 0.1384  loss_box_reg: 0.1769  total_val_loss: 0.4823  val_loss_cls: 0.1896  val_loss_box_reg: 0.3091    time: 1.0386  last_time: 1.0989  data_time: 0.0361  last_data_time: 0.0125   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:02:19 d2.utils.events]: \u001b[0m eta: 1:09:30  iter: 2179  total_loss: 0.4316  loss_cls: 0.201  loss_box_reg: 0.2397  total_val_loss: 0.3727  val_loss_cls: 0.1646  val_loss_box_reg: 0.2345    time: 1.0386  last_time: 1.1128  data_time: 0.0294  last_data_time: 0.0149   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:02:49 d2.utils.events]: \u001b[0m eta: 1:09:00  iter: 2199  total_loss: 0.4176  loss_cls: 0.1886  loss_box_reg: 0.2476  total_val_loss: 0.4658  val_loss_cls: 0.1769  val_loss_box_reg: 0.2712    time: 1.0385  last_time: 1.1624  data_time: 0.0301  last_data_time: 0.0465   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:03:19 d2.utils.events]: \u001b[0m eta: 1:07:12  iter: 2219  total_loss: 0.3404  loss_cls: 0.1352  loss_box_reg: 0.1954  total_val_loss: 0.518  val_loss_cls: 0.2193  val_loss_box_reg: 0.298    time: 1.0384  last_time: 1.1195  data_time: 0.0387  last_data_time: 0.0344   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:03:49 d2.utils.events]: \u001b[0m eta: 1:06:51  iter: 2239  total_loss: 0.4427  loss_cls: 0.1839  loss_box_reg: 0.2428  total_val_loss: 0.506  val_loss_cls: 0.1993  val_loss_box_reg: 0.2869    time: 1.0385  last_time: 1.1164  data_time: 0.0291  last_data_time: 0.0342   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:04:20 d2.utils.events]: \u001b[0m eta: 1:08:00  iter: 2259  total_loss: 0.3294  loss_cls: 0.1303  loss_box_reg: 0.205  total_val_loss: 0.4509  val_loss_cls: 0.1842  val_loss_box_reg: 0.2652    time: 1.0388  last_time: 0.9067  data_time: 0.0360  last_data_time: 0.0582   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:04:50 d2.utils.events]: \u001b[0m eta: 1:07:41  iter: 2279  total_loss: 0.4031  loss_cls: 0.1739  loss_box_reg: 0.2494  total_val_loss: 0.5761  val_loss_cls: 0.2141  val_loss_box_reg: 0.3477    time: 1.0389  last_time: 1.0161  data_time: 0.0371  last_data_time: 0.0581   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:05:20 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 2299  total_loss: 0.3455  loss_cls: 0.1464  loss_box_reg: 0.1907  total_val_loss: 0.554  val_loss_cls: 0.2044  val_loss_box_reg: 0.3377    time: 1.0389  last_time: 0.7190  data_time: 0.0430  last_data_time: 0.0295   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:05:50 d2.utils.events]: \u001b[0m eta: 1:06:59  iter: 2319  total_loss: 0.4235  loss_cls: 0.1861  loss_box_reg: 0.2402  total_val_loss: 0.4536  val_loss_cls: 0.1905  val_loss_box_reg: 0.2604    time: 1.0390  last_time: 0.9905  data_time: 0.0318  last_data_time: 0.0699   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:06:21 d2.utils.events]: \u001b[0m eta: 1:06:38  iter: 2339  total_loss: 0.4073  loss_cls: 0.172  loss_box_reg: 0.2273  total_val_loss: 0.4533  val_loss_cls: 0.1836  val_loss_box_reg: 0.2774    time: 1.0393  last_time: 1.1192  data_time: 0.0257  last_data_time: 0.0203   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:06:51 d2.utils.events]: \u001b[0m eta: 1:06:16  iter: 2359  total_loss: 0.3725  loss_cls: 0.1504  loss_box_reg: 0.1957  total_val_loss: 0.4976  val_loss_cls: 0.1894  val_loss_box_reg: 0.2988    time: 1.0391  last_time: 0.9771  data_time: 0.0365  last_data_time: 0.0390   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:07:21 d2.utils.events]: \u001b[0m eta: 1:05:54  iter: 2379  total_loss: 0.3892  loss_cls: 0.1726  loss_box_reg: 0.2046  total_val_loss: 0.4834  val_loss_cls: 0.194  val_loss_box_reg: 0.2875    time: 1.0390  last_time: 1.1015  data_time: 0.0325  last_data_time: 0.0102   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:07:50 d2.utils.events]: \u001b[0m eta: 1:02:45  iter: 2399  total_loss: 0.4197  loss_cls: 0.1749  loss_box_reg: 0.2371  total_val_loss: 0.4895  val_loss_cls: 0.193  val_loss_box_reg: 0.302    time: 1.0387  last_time: 1.0231  data_time: 0.0327  last_data_time: 0.0641   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:08:19 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 2419  total_loss: 0.3819  loss_cls: 0.1588  loss_box_reg: 0.2113  total_val_loss: 0.4834  val_loss_cls: 0.2098  val_loss_box_reg: 0.2836    time: 1.0386  last_time: 1.1138  data_time: 0.0311  last_data_time: 0.0302   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:08:49 d2.utils.events]: \u001b[0m eta: 1:03:22  iter: 2439  total_loss: 0.4329  loss_cls: 0.1729  loss_box_reg: 0.2624  total_val_loss: 0.4294  val_loss_cls: 0.1609  val_loss_box_reg: 0.2686    time: 1.0386  last_time: 1.1268  data_time: 0.0364  last_data_time: 0.0368   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:09:20 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 2459  total_loss: 0.3904  loss_cls: 0.1683  loss_box_reg: 0.2254  total_val_loss: 0.5064  val_loss_cls: 0.1926  val_loss_box_reg: 0.3097    time: 1.0388  last_time: 1.1649  data_time: 0.0396  last_data_time: 0.0581   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:09:49 d2.utils.events]: \u001b[0m eta: 1:00:59  iter: 2479  total_loss: 0.3782  loss_cls: 0.1553  loss_box_reg: 0.2156  total_val_loss: 0.4628  val_loss_cls: 0.1826  val_loss_box_reg: 0.2848    time: 1.0385  last_time: 1.0296  data_time: 0.0372  last_data_time: 0.0637   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:10:23 d2.utils.events]: \u001b[0m eta: 0:59:54  iter: 2499  total_loss: 0.3464  loss_cls: 0.155  loss_box_reg: 0.204  total_val_loss: 0.5191  val_loss_cls: 0.1806  val_loss_box_reg: 0.3403    time: 1.0383  last_time: 1.1120  data_time: 0.0307  last_data_time: 0.0146   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:10:53 d2.utils.events]: \u001b[0m eta: 0:59:30  iter: 2519  total_loss: 0.4721  loss_cls: 0.209  loss_box_reg: 0.2467  total_val_loss: 0.4686  val_loss_cls: 0.1679  val_loss_box_reg: 0.2731    time: 1.0382  last_time: 1.1280  data_time: 0.0346  last_data_time: 0.0349   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:11:22 d2.utils.events]: \u001b[0m eta: 0:59:08  iter: 2539  total_loss: 0.3613  loss_cls: 0.1708  loss_box_reg: 0.1921  total_val_loss: 0.4746  val_loss_cls: 0.1932  val_loss_box_reg: 0.2801    time: 1.0383  last_time: 0.9353  data_time: 0.0363  last_data_time: 0.0340   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:11:52 d2.utils.events]: \u001b[0m eta: 0:58:49  iter: 2559  total_loss: 0.374  loss_cls: 0.1674  loss_box_reg: 0.2139  total_val_loss: 0.3681  val_loss_cls: 0.1529  val_loss_box_reg: 0.2169    time: 1.0383  last_time: 1.1274  data_time: 0.0326  last_data_time: 0.0182   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:12:22 d2.utils.events]: \u001b[0m eta: 0:58:27  iter: 2579  total_loss: 0.3754  loss_cls: 0.1635  loss_box_reg: 0.2255  total_val_loss: 0.4158  val_loss_cls: 0.1743  val_loss_box_reg: 0.2685    time: 1.0384  last_time: 0.9506  data_time: 0.0346  last_data_time: 0.0115   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:12:52 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 2599  total_loss: 0.3599  loss_cls: 0.1732  loss_box_reg: 0.2118  total_val_loss: 0.4373  val_loss_cls: 0.1633  val_loss_box_reg: 0.2631    time: 1.0385  last_time: 0.9677  data_time: 0.0435  last_data_time: 0.0329   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:13:22 d2.utils.events]: \u001b[0m eta: 0:57:41  iter: 2619  total_loss: 0.3796  loss_cls: 0.1594  loss_box_reg: 0.2291  total_val_loss: 0.4481  val_loss_cls: 0.1744  val_loss_box_reg: 0.2719    time: 1.0385  last_time: 1.1309  data_time: 0.0324  last_data_time: 0.0268   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:13:51 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 2639  total_loss: 0.3584  loss_cls: 0.1358  loss_box_reg: 0.2211  total_val_loss: 0.4854  val_loss_cls: 0.1835  val_loss_box_reg: 0.29    time: 1.0384  last_time: 0.9836  data_time: 0.0361  last_data_time: 0.0376   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:14:22 d2.utils.events]: \u001b[0m eta: 0:56:58  iter: 2659  total_loss: 0.3657  loss_cls: 0.1388  loss_box_reg: 0.2262  total_val_loss: 0.5631  val_loss_cls: 0.2239  val_loss_box_reg: 0.3432    time: 1.0386  last_time: 1.1277  data_time: 0.0342  last_data_time: 0.0351   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:14:52 d2.utils.events]: \u001b[0m eta: 0:56:38  iter: 2679  total_loss: 0.4293  loss_cls: 0.1614  loss_box_reg: 0.2637  total_val_loss: 0.4281  val_loss_cls: 0.174  val_loss_box_reg: 0.2686    time: 1.0386  last_time: 1.1005  data_time: 0.0315  last_data_time: 0.0124   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:15:22 d2.utils.events]: \u001b[0m eta: 0:56:22  iter: 2699  total_loss: 0.4416  loss_cls: 0.1742  loss_box_reg: 0.2661  total_val_loss: 0.4558  val_loss_cls: 0.185  val_loss_box_reg: 0.2771    time: 1.0388  last_time: 1.1653  data_time: 0.0350  last_data_time: 0.0611   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:15:52 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 2719  total_loss: 0.3695  loss_cls: 0.1533  loss_box_reg: 0.222  total_val_loss: 0.4803  val_loss_cls: 0.1736  val_loss_box_reg: 0.2893    time: 1.0387  last_time: 0.9793  data_time: 0.0307  last_data_time: 0.0636   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:16:22 d2.utils.events]: \u001b[0m eta: 0:55:50  iter: 2739  total_loss: 0.3443  loss_cls: 0.1504  loss_box_reg: 0.1911  total_val_loss: 0.504  val_loss_cls: 0.2007  val_loss_box_reg: 0.2965    time: 1.0388  last_time: 1.1223  data_time: 0.0334  last_data_time: 0.0386   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:16:52 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 2759  total_loss: 0.3396  loss_cls: 0.1358  loss_box_reg: 0.2153  total_val_loss: 0.4155  val_loss_cls: 0.1577  val_loss_box_reg: 0.2614    time: 1.0389  last_time: 0.9698  data_time: 0.0357  last_data_time: 0.0343   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:17:22 d2.utils.events]: \u001b[0m eta: 0:55:12  iter: 2779  total_loss: 0.4255  loss_cls: 0.1686  loss_box_reg: 0.251  total_val_loss: 0.4616  val_loss_cls: 0.1714  val_loss_box_reg: 0.2872    time: 1.0389  last_time: 1.1665  data_time: 0.0303  last_data_time: 0.0575   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:17:52 d2.utils.events]: \u001b[0m eta: 0:54:38  iter: 2799  total_loss: 0.4172  loss_cls: 0.1681  loss_box_reg: 0.2461  total_val_loss: 0.4389  val_loss_cls: 0.1716  val_loss_box_reg: 0.251    time: 1.0388  last_time: 0.9753  data_time: 0.0322  last_data_time: 0.0206   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:18:22 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 2819  total_loss: 0.401  loss_cls: 0.182  loss_box_reg: 0.2179  total_val_loss: 0.4358  val_loss_cls: 0.1644  val_loss_box_reg: 0.2805    time: 1.0388  last_time: 1.1048  data_time: 0.0310  last_data_time: 0.0135   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:18:52 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 2839  total_loss: 0.32  loss_cls: 0.1442  loss_box_reg: 0.1698  total_val_loss: 0.4432  val_loss_cls: 0.1746  val_loss_box_reg: 0.2823    time: 1.0388  last_time: 1.1403  data_time: 0.0279  last_data_time: 0.0479   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:19:22 d2.utils.events]: \u001b[0m eta: 0:53:40  iter: 2859  total_loss: 0.3288  loss_cls: 0.1426  loss_box_reg: 0.191  total_val_loss: 0.5656  val_loss_cls: 0.2189  val_loss_box_reg: 0.343    time: 1.0389  last_time: 1.1213  data_time: 0.0356  last_data_time: 0.0102   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:19:51 d2.utils.events]: \u001b[0m eta: 0:53:33  iter: 2879  total_loss: 0.3745  loss_cls: 0.1621  loss_box_reg: 0.1961  total_val_loss: 0.4472  val_loss_cls: 0.1798  val_loss_box_reg: 0.2707    time: 1.0387  last_time: 0.9457  data_time: 0.0340  last_data_time: 0.0135   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:20:21 d2.utils.events]: \u001b[0m eta: 0:53:14  iter: 2899  total_loss: 0.4328  loss_cls: 0.1796  loss_box_reg: 0.227  total_val_loss: 0.4511  val_loss_cls: 0.1749  val_loss_box_reg: 0.2804    time: 1.0387  last_time: 1.1360  data_time: 0.0388  last_data_time: 0.0472   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:20:51 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 2919  total_loss: 0.4062  loss_cls: 0.1833  loss_box_reg: 0.2165  total_val_loss: 0.482  val_loss_cls: 0.1891  val_loss_box_reg: 0.2878    time: 1.0387  last_time: 0.9445  data_time: 0.0287  last_data_time: 0.0112   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:21:21 d2.utils.events]: \u001b[0m eta: 0:52:59  iter: 2939  total_loss: 0.3365  loss_cls: 0.1413  loss_box_reg: 0.199  total_val_loss: 0.4377  val_loss_cls: 0.1655  val_loss_box_reg: 0.2648    time: 1.0387  last_time: 1.0136  data_time: 0.0368  last_data_time: 0.0592   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:21:51 d2.utils.events]: \u001b[0m eta: 0:52:40  iter: 2959  total_loss: 0.4338  loss_cls: 0.1913  loss_box_reg: 0.2654  total_val_loss: 0.4355  val_loss_cls: 0.1617  val_loss_box_reg: 0.2702    time: 1.0388  last_time: 0.9385  data_time: 0.0330  last_data_time: 0.0360   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:22:22 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 2979  total_loss: 0.3365  loss_cls: 0.1296  loss_box_reg: 0.2052  total_val_loss: 0.449  val_loss_cls: 0.1721  val_loss_box_reg: 0.2802    time: 1.0391  last_time: 1.1277  data_time: 0.0410  last_data_time: 0.0321   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:22:54 d2.utils.events]: \u001b[0m eta: 0:54:35  iter: 2999  total_loss: 0.4061  loss_cls: 0.1495  loss_box_reg: 0.2406  total_val_loss: 0.4927  val_loss_cls: 0.196  val_loss_box_reg: 0.2951    time: 1.0392  last_time: 0.9685  data_time: 0.0408  last_data_time: 0.0327   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:23:24 d2.utils.events]: \u001b[0m eta: 0:54:24  iter: 3019  total_loss: 0.4664  loss_cls: 0.1702  loss_box_reg: 0.2787  total_val_loss: 0.4152  val_loss_cls: 0.1801  val_loss_box_reg: 0.2356    time: 1.0394  last_time: 1.1434  data_time: 0.0341  last_data_time: 0.0583   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:23:54 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 3039  total_loss: 0.3512  loss_cls: 0.155  loss_box_reg: 0.178  total_val_loss: 0.4382  val_loss_cls: 0.1714  val_loss_box_reg: 0.2699    time: 1.0395  last_time: 1.0076  data_time: 0.0303  last_data_time: 0.0551   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:24:25 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 3059  total_loss: 0.3514  loss_cls: 0.139  loss_box_reg: 0.195  total_val_loss: 0.4873  val_loss_cls: 0.1651  val_loss_box_reg: 0.2861    time: 1.0398  last_time: 1.1250  data_time: 0.0380  last_data_time: 0.0363   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:24:54 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 3079  total_loss: 0.3491  loss_cls: 0.1411  loss_box_reg: 0.205  total_val_loss: 0.4412  val_loss_cls: 0.1694  val_loss_box_reg: 0.282    time: 1.0398  last_time: 0.8423  data_time: 0.0332  last_data_time: 0.0126   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:25:24 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 3099  total_loss: 0.4078  loss_cls: 0.1657  loss_box_reg: 0.2314  total_val_loss: 0.4717  val_loss_cls: 0.1843  val_loss_box_reg: 0.2859    time: 1.0398  last_time: 1.0026  data_time: 0.0316  last_data_time: 0.0485   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:25:54 d2.utils.events]: \u001b[0m eta: 0:52:24  iter: 3119  total_loss: 0.3964  loss_cls: 0.144  loss_box_reg: 0.2519  total_val_loss: 0.4036  val_loss_cls: 0.161  val_loss_box_reg: 0.2454    time: 1.0396  last_time: 1.1621  data_time: 0.0242  last_data_time: 0.0519   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:26:24 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 3139  total_loss: 0.3797  loss_cls: 0.164  loss_box_reg: 0.2157  total_val_loss: 0.5429  val_loss_cls: 0.2163  val_loss_box_reg: 0.3283    time: 1.0397  last_time: 0.9562  data_time: 0.0319  last_data_time: 0.0273   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:26:55 d2.utils.events]: \u001b[0m eta: 0:51:55  iter: 3159  total_loss: 0.3882  loss_cls: 0.1562  loss_box_reg: 0.227  total_val_loss: 0.4919  val_loss_cls: 0.1853  val_loss_box_reg: 0.3029    time: 1.0400  last_time: 1.1192  data_time: 0.0384  last_data_time: 0.0332   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:27:25 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 3179  total_loss: 0.325  loss_cls: 0.1409  loss_box_reg: 0.1878  total_val_loss: 0.4661  val_loss_cls: 0.1696  val_loss_box_reg: 0.2739    time: 1.0400  last_time: 1.1637  data_time: 0.0263  last_data_time: 0.0587   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:27:55 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 3199  total_loss: 0.3782  loss_cls: 0.1497  loss_box_reg: 0.221  total_val_loss: 0.3894  val_loss_cls: 0.1557  val_loss_box_reg: 0.2336    time: 1.0402  last_time: 0.9633  data_time: 0.0309  last_data_time: 0.0465   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:28:25 d2.utils.events]: \u001b[0m eta: 0:50:55  iter: 3219  total_loss: 0.4069  loss_cls: 0.1583  loss_box_reg: 0.2325  total_val_loss: 0.4457  val_loss_cls: 0.1767  val_loss_box_reg: 0.2839    time: 1.0403  last_time: 1.1258  data_time: 0.0334  last_data_time: 0.0350   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:28:56 d2.utils.events]: \u001b[0m eta: 0:50:35  iter: 3239  total_loss: 0.4017  loss_cls: 0.1814  loss_box_reg: 0.2139  total_val_loss: 0.4316  val_loss_cls: 0.1787  val_loss_box_reg: 0.2562    time: 1.0405  last_time: 1.1332  data_time: 0.0309  last_data_time: 0.0400   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:29:26 d2.utils.events]: \u001b[0m eta: 0:50:11  iter: 3259  total_loss: 0.3327  loss_cls: 0.1453  loss_box_reg: 0.1925  total_val_loss: 0.4107  val_loss_cls: 0.1579  val_loss_box_reg: 0.2575    time: 1.0406  last_time: 0.8777  data_time: 0.0404  last_data_time: 0.0458   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:29:56 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 3279  total_loss: 0.4177  loss_cls: 0.1707  loss_box_reg: 0.2472  total_val_loss: 0.4539  val_loss_cls: 0.1696  val_loss_box_reg: 0.2907    time: 1.0407  last_time: 0.9290  data_time: 0.0349  last_data_time: 0.0117   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:30:27 d2.utils.events]: \u001b[0m eta: 0:49:29  iter: 3299  total_loss: 0.3485  loss_cls: 0.1403  loss_box_reg: 0.2082  total_val_loss: 0.4925  val_loss_cls: 0.1967  val_loss_box_reg: 0.2928    time: 1.0410  last_time: 1.1207  data_time: 0.0315  last_data_time: 0.0332   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:30:57 d2.utils.events]: \u001b[0m eta: 0:49:07  iter: 3319  total_loss: 0.3895  loss_cls: 0.1564  loss_box_reg: 0.2374  total_val_loss: 0.4745  val_loss_cls: 0.182  val_loss_box_reg: 0.2807    time: 1.0410  last_time: 0.9766  data_time: 0.0368  last_data_time: 0.0391   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:31:27 d2.utils.events]: \u001b[0m eta: 0:48:42  iter: 3339  total_loss: 0.3937  loss_cls: 0.1689  loss_box_reg: 0.251  total_val_loss: 0.4323  val_loss_cls: 0.1652  val_loss_box_reg: 0.2655    time: 1.0409  last_time: 0.9687  data_time: 0.0324  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:31:57 d2.utils.events]: \u001b[0m eta: 0:48:21  iter: 3359  total_loss: 0.3514  loss_cls: 0.1353  loss_box_reg: 0.2054  total_val_loss: 0.4546  val_loss_cls: 0.1636  val_loss_box_reg: 0.2847    time: 1.0410  last_time: 1.1411  data_time: 0.0276  last_data_time: 0.0119   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:32:27 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 3379  total_loss: 0.3195  loss_cls: 0.1244  loss_box_reg: 0.1775  total_val_loss: 0.4603  val_loss_cls: 0.1643  val_loss_box_reg: 0.2879    time: 1.0410  last_time: 0.8164  data_time: 0.0330  last_data_time: 0.0322   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:32:56 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 3399  total_loss: 0.4168  loss_cls: 0.1767  loss_box_reg: 0.2418  total_val_loss: 0.4867  val_loss_cls: 0.1936  val_loss_box_reg: 0.2872    time: 1.0410  last_time: 0.9672  data_time: 0.0308  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:33:25 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 3419  total_loss: 0.372  loss_cls: 0.1669  loss_box_reg: 0.2158  total_val_loss: 0.4452  val_loss_cls: 0.1818  val_loss_box_reg: 0.2625    time: 1.0407  last_time: 0.9789  data_time: 0.0328  last_data_time: 0.0589   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:33:55 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 3439  total_loss: 0.3017  loss_cls: 0.1232  loss_box_reg: 0.1787  total_val_loss: 0.4501  val_loss_cls: 0.1863  val_loss_box_reg: 0.2574    time: 1.0406  last_time: 0.9729  data_time: 0.0317  last_data_time: 0.0572   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:34:25 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 3459  total_loss: 0.3474  loss_cls: 0.1486  loss_box_reg: 0.215  total_val_loss: 0.3889  val_loss_cls: 0.1622  val_loss_box_reg: 0.2276    time: 1.0407  last_time: 1.1042  data_time: 0.0362  last_data_time: 0.0123   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:34:54 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 3479  total_loss: 0.3668  loss_cls: 0.1442  loss_box_reg: 0.2131  total_val_loss: 0.4822  val_loss_cls: 0.1878  val_loss_box_reg: 0.2931    time: 1.0406  last_time: 0.9126  data_time: 0.0341  last_data_time: 0.0117   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:35:25 d2.utils.events]: \u001b[0m eta: 0:45:50  iter: 3499  total_loss: 0.3704  loss_cls: 0.1534  loss_box_reg: 0.2185  total_val_loss: 0.4465  val_loss_cls: 0.1706  val_loss_box_reg: 0.2931    time: 1.0405  last_time: 1.1408  data_time: 0.0362  last_data_time: 0.0326   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:35:55 d2.utils.events]: \u001b[0m eta: 0:45:28  iter: 3519  total_loss: 0.3179  loss_cls: 0.1263  loss_box_reg: 0.1699  total_val_loss: 0.4312  val_loss_cls: 0.1498  val_loss_box_reg: 0.2573    time: 1.0406  last_time: 1.1659  data_time: 0.0280  last_data_time: 0.0507   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:36:25 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 3539  total_loss: 0.4182  loss_cls: 0.1633  loss_box_reg: 0.2491  total_val_loss: 0.417  val_loss_cls: 0.1629  val_loss_box_reg: 0.2542    time: 1.0404  last_time: 0.9676  data_time: 0.0294  last_data_time: 0.0295   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:36:55 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 3559  total_loss: 0.4244  loss_cls: 0.1774  loss_box_reg: 0.2515  total_val_loss: 0.4541  val_loss_cls: 0.1878  val_loss_box_reg: 0.2697    time: 1.0404  last_time: 0.9693  data_time: 0.0340  last_data_time: 0.0337   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:37:25 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 3579  total_loss: 0.3893  loss_cls: 0.1593  loss_box_reg: 0.2319  total_val_loss: 0.4255  val_loss_cls: 0.1598  val_loss_box_reg: 0.2551    time: 1.0405  last_time: 1.1129  data_time: 0.0356  last_data_time: 0.0096   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:37:54 d2.utils.events]: \u001b[0m eta: 0:43:58  iter: 3599  total_loss: 0.3767  loss_cls: 0.1626  loss_box_reg: 0.2343  total_val_loss: 0.4873  val_loss_cls: 0.1753  val_loss_box_reg: 0.3011    time: 1.0403  last_time: 0.9530  data_time: 0.0310  last_data_time: 0.0337   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:38:24 d2.utils.events]: \u001b[0m eta: 0:43:36  iter: 3619  total_loss: 0.3596  loss_cls: 0.1585  loss_box_reg: 0.207  total_val_loss: 0.5108  val_loss_cls: 0.1944  val_loss_box_reg: 0.3055    time: 1.0403  last_time: 0.8666  data_time: 0.0375  last_data_time: 0.0355   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:38:54 d2.utils.events]: \u001b[0m eta: 0:43:14  iter: 3639  total_loss: 0.3227  loss_cls: 0.1279  loss_box_reg: 0.1924  total_val_loss: 0.4639  val_loss_cls: 0.1725  val_loss_box_reg: 0.2881    time: 1.0404  last_time: 1.1193  data_time: 0.0405  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:39:24 d2.utils.events]: \u001b[0m eta: 0:42:50  iter: 3659  total_loss: 0.3875  loss_cls: 0.1446  loss_box_reg: 0.2418  total_val_loss: 0.4877  val_loss_cls: 0.1766  val_loss_box_reg: 0.2864    time: 1.0403  last_time: 1.1330  data_time: 0.0356  last_data_time: 0.0316   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:39:54 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 3679  total_loss: 0.3705  loss_cls: 0.1361  loss_box_reg: 0.2343  total_val_loss: 0.5146  val_loss_cls: 0.203  val_loss_box_reg: 0.3082    time: 1.0403  last_time: 1.1402  data_time: 0.0242  last_data_time: 0.0343   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:40:24 d2.utils.events]: \u001b[0m eta: 0:42:06  iter: 3699  total_loss: 0.3973  loss_cls: 0.1686  loss_box_reg: 0.2266  total_val_loss: 0.4442  val_loss_cls: 0.1672  val_loss_box_reg: 0.277    time: 1.0403  last_time: 1.1238  data_time: 0.0352  last_data_time: 0.0342   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:40:54 d2.utils.events]: \u001b[0m eta: 0:41:46  iter: 3719  total_loss: 0.346  loss_cls: 0.1342  loss_box_reg: 0.1975  total_val_loss: 0.4922  val_loss_cls: 0.1877  val_loss_box_reg: 0.3041    time: 1.0404  last_time: 0.9627  data_time: 0.0303  last_data_time: 0.0219   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:41:24 d2.utils.events]: \u001b[0m eta: 0:41:24  iter: 3739  total_loss: 0.3847  loss_cls: 0.1676  loss_box_reg: 0.2282  total_val_loss: 0.429  val_loss_cls: 0.1574  val_loss_box_reg: 0.2618    time: 1.0406  last_time: 1.1605  data_time: 0.0388  last_data_time: 0.0513   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:41:55 d2.utils.events]: \u001b[0m eta: 0:41:03  iter: 3759  total_loss: 0.3786  loss_cls: 0.1665  loss_box_reg: 0.2379  total_val_loss: 0.4571  val_loss_cls: 0.1728  val_loss_box_reg: 0.2799    time: 1.0407  last_time: 1.1577  data_time: 0.0321  last_data_time: 0.0559   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:42:24 d2.utils.events]: \u001b[0m eta: 0:40:39  iter: 3779  total_loss: 0.2933  loss_cls: 0.1365  loss_box_reg: 0.1784  total_val_loss: 0.537  val_loss_cls: 0.2049  val_loss_box_reg: 0.338    time: 1.0405  last_time: 0.9745  data_time: 0.0354  last_data_time: 0.0348   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:42:54 d2.utils.events]: \u001b[0m eta: 0:40:19  iter: 3799  total_loss: 0.4109  loss_cls: 0.1628  loss_box_reg: 0.222  total_val_loss: 0.5109  val_loss_cls: 0.1945  val_loss_box_reg: 0.3142    time: 1.0406  last_time: 1.1063  data_time: 0.0362  last_data_time: 0.0128   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:43:25 d2.utils.events]: \u001b[0m eta: 0:39:56  iter: 3819  total_loss: 0.3643  loss_cls: 0.143  loss_box_reg: 0.2118  total_val_loss: 0.4675  val_loss_cls: 0.1702  val_loss_box_reg: 0.2859    time: 1.0407  last_time: 1.1481  data_time: 0.0390  last_data_time: 0.0333   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:43:54 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 3839  total_loss: 0.3962  loss_cls: 0.1592  loss_box_reg: 0.2152  total_val_loss: 0.4203  val_loss_cls: 0.1594  val_loss_box_reg: 0.246    time: 1.0406  last_time: 0.9649  data_time: 0.0314  last_data_time: 0.0136   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:44:24 d2.utils.events]: \u001b[0m eta: 0:39:11  iter: 3859  total_loss: 0.3923  loss_cls: 0.1591  loss_box_reg: 0.2107  total_val_loss: 0.4296  val_loss_cls: 0.1687  val_loss_box_reg: 0.2608    time: 1.0406  last_time: 0.9666  data_time: 0.0354  last_data_time: 0.0321   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:44:55 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 3879  total_loss: 0.3066  loss_cls: 0.1184  loss_box_reg: 0.1937  total_val_loss: 0.4974  val_loss_cls: 0.194  val_loss_box_reg: 0.3051    time: 1.0407  last_time: 1.1238  data_time: 0.0332  last_data_time: 0.0351   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:45:24 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 3899  total_loss: 0.3666  loss_cls: 0.1585  loss_box_reg: 0.2074  total_val_loss: 0.438  val_loss_cls: 0.1739  val_loss_box_reg: 0.2578    time: 1.0405  last_time: 1.1638  data_time: 0.0364  last_data_time: 0.0580   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:45:53 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 3919  total_loss: 0.3997  loss_cls: 0.1626  loss_box_reg: 0.2528  total_val_loss: 0.4338  val_loss_cls: 0.1768  val_loss_box_reg: 0.2672    time: 1.0406  last_time: 1.1206  data_time: 0.0296  last_data_time: 0.0301   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:46:23 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 3939  total_loss: 0.342  loss_cls: 0.1302  loss_box_reg: 0.2103  total_val_loss: 0.4937  val_loss_cls: 0.1853  val_loss_box_reg: 0.2946    time: 1.0406  last_time: 1.1255  data_time: 0.0267  last_data_time: 0.0368   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:46:53 d2.utils.events]: \u001b[0m eta: 0:37:23  iter: 3959  total_loss: 0.384  loss_cls: 0.1581  loss_box_reg: 0.2189  total_val_loss: 0.4529  val_loss_cls: 0.1704  val_loss_box_reg: 0.2864    time: 1.0406  last_time: 1.1233  data_time: 0.0332  last_data_time: 0.0344   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:47:22 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 3979  total_loss: 0.387  loss_cls: 0.1555  loss_box_reg: 0.2256  total_val_loss: 0.4321  val_loss_cls: 0.1801  val_loss_box_reg: 0.2514    time: 1.0406  last_time: 1.1389  data_time: 0.0389  last_data_time: 0.0276   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:47:54 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 3999  total_loss: 0.4222  loss_cls: 0.1571  loss_box_reg: 0.2578  total_val_loss: 0.4321  val_loss_cls: 0.1638  val_loss_box_reg: 0.2572    time: 1.0405  last_time: 0.9397  data_time: 0.0317  last_data_time: 0.0359   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:48:25 d2.utils.events]: \u001b[0m eta: 0:36:14  iter: 4019  total_loss: 0.3779  loss_cls: 0.1708  loss_box_reg: 0.2098  total_val_loss: 0.3795  val_loss_cls: 0.1483  val_loss_box_reg: 0.2395    time: 1.0407  last_time: 0.9733  data_time: 0.0408  last_data_time: 0.0335   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:48:55 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 4039  total_loss: 0.3419  loss_cls: 0.143  loss_box_reg: 0.2163  total_val_loss: 0.3629  val_loss_cls: 0.1406  val_loss_box_reg: 0.2256    time: 1.0407  last_time: 0.9525  data_time: 0.0341  last_data_time: 0.0117   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:49:24 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 4059  total_loss: 0.383  loss_cls: 0.1424  loss_box_reg: 0.218  total_val_loss: 0.4003  val_loss_cls: 0.1503  val_loss_box_reg: 0.2544    time: 1.0406  last_time: 1.1588  data_time: 0.0298  last_data_time: 0.0441   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:49:54 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 4079  total_loss: 0.392  loss_cls: 0.1467  loss_box_reg: 0.2502  total_val_loss: 0.5077  val_loss_cls: 0.1893  val_loss_box_reg: 0.3347    time: 1.0406  last_time: 1.1120  data_time: 0.0274  last_data_time: 0.0091   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:50:25 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 4099  total_loss: 0.3143  loss_cls: 0.1304  loss_box_reg: 0.1839  total_val_loss: 0.4857  val_loss_cls: 0.167  val_loss_box_reg: 0.3078    time: 1.0407  last_time: 1.1263  data_time: 0.0346  last_data_time: 0.0377   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:50:55 d2.utils.events]: \u001b[0m eta: 0:34:24  iter: 4119  total_loss: 0.4242  loss_cls: 0.177  loss_box_reg: 0.263  total_val_loss: 0.5197  val_loss_cls: 0.2  val_loss_box_reg: 0.3153    time: 1.0408  last_time: 1.1046  data_time: 0.0332  last_data_time: 0.0120   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:51:25 d2.utils.events]: \u001b[0m eta: 0:34:00  iter: 4139  total_loss: 0.3318  loss_cls: 0.1413  loss_box_reg: 0.1995  total_val_loss: 0.4497  val_loss_cls: 0.1767  val_loss_box_reg: 0.2852    time: 1.0409  last_time: 1.1192  data_time: 0.0310  last_data_time: 0.0103   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:51:54 d2.utils.events]: \u001b[0m eta: 0:33:34  iter: 4159  total_loss: 0.4219  loss_cls: 0.1714  loss_box_reg: 0.2506  total_val_loss: 0.4461  val_loss_cls: 0.1677  val_loss_box_reg: 0.2725    time: 1.0408  last_time: 0.9805  data_time: 0.0270  last_data_time: 0.0184   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:52:24 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 4179  total_loss: 0.3113  loss_cls: 0.1285  loss_box_reg: 0.1879  total_val_loss: 0.3964  val_loss_cls: 0.1462  val_loss_box_reg: 0.2488    time: 1.0408  last_time: 0.9613  data_time: 0.0314  last_data_time: 0.0326   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:52:55 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 4199  total_loss: 0.3803  loss_cls: 0.1555  loss_box_reg: 0.2241  total_val_loss: 0.4356  val_loss_cls: 0.1689  val_loss_box_reg: 0.2667    time: 1.0409  last_time: 1.1060  data_time: 0.0327  last_data_time: 0.0135   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:53:24 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 4219  total_loss: 0.3212  loss_cls: 0.1314  loss_box_reg: 0.1976  total_val_loss: 0.492  val_loss_cls: 0.1939  val_loss_box_reg: 0.3171    time: 1.0409  last_time: 1.1193  data_time: 0.0283  last_data_time: 0.0104   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:53:54 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 4239  total_loss: 0.383  loss_cls: 0.1551  loss_box_reg: 0.2292  total_val_loss: 0.3878  val_loss_cls: 0.1553  val_loss_box_reg: 0.244    time: 1.0408  last_time: 0.9463  data_time: 0.0263  last_data_time: 0.0149   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:54:24 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 4259  total_loss: 0.3606  loss_cls: 0.1502  loss_box_reg: 0.2141  total_val_loss: 0.5433  val_loss_cls: 0.2191  val_loss_box_reg: 0.3189    time: 1.0408  last_time: 1.1180  data_time: 0.0274  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:54:54 d2.utils.events]: \u001b[0m eta: 0:29:42  iter: 4279  total_loss: 0.2975  loss_cls: 0.1311  loss_box_reg: 0.1699  total_val_loss: 0.4408  val_loss_cls: 0.1721  val_loss_box_reg: 0.2809    time: 1.0409  last_time: 1.1274  data_time: 0.0343  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:55:24 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 4299  total_loss: 0.3887  loss_cls: 0.1613  loss_box_reg: 0.2409  total_val_loss: 0.4059  val_loss_cls: 0.1621  val_loss_box_reg: 0.2411    time: 1.0409  last_time: 0.9812  data_time: 0.0282  last_data_time: 0.0145   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:55:54 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 4319  total_loss: 0.4964  loss_cls: 0.1954  loss_box_reg: 0.2857  total_val_loss: 0.375  val_loss_cls: 0.1483  val_loss_box_reg: 0.2413    time: 1.0409  last_time: 1.0192  data_time: 0.0321  last_data_time: 0.0637   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:56:23 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 4339  total_loss: 0.3688  loss_cls: 0.1346  loss_box_reg: 0.2277  total_val_loss: 0.477  val_loss_cls: 0.1757  val_loss_box_reg: 0.2982    time: 1.0408  last_time: 1.1026  data_time: 0.0332  last_data_time: 0.0129   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:56:53 d2.utils.events]: \u001b[0m eta: 0:27:56  iter: 4359  total_loss: 0.3532  loss_cls: 0.1487  loss_box_reg: 0.226  total_val_loss: 0.3813  val_loss_cls: 0.1453  val_loss_box_reg: 0.2382    time: 1.0407  last_time: 0.9191  data_time: 0.0237  last_data_time: 0.0125   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:57:23 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 4379  total_loss: 0.3399  loss_cls: 0.1306  loss_box_reg: 0.2033  total_val_loss: 0.45  val_loss_cls: 0.1769  val_loss_box_reg: 0.2719    time: 1.0406  last_time: 1.0040  data_time: 0.0349  last_data_time: 0.0515   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:57:52 d2.utils.events]: \u001b[0m eta: 0:27:15  iter: 4399  total_loss: 0.3966  loss_cls: 0.1675  loss_box_reg: 0.2271  total_val_loss: 0.4127  val_loss_cls: 0.16  val_loss_box_reg: 0.2709    time: 1.0407  last_time: 1.1401  data_time: 0.0370  last_data_time: 0.0353   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:58:22 d2.utils.events]: \u001b[0m eta: 0:27:14  iter: 4419  total_loss: 0.3292  loss_cls: 0.1414  loss_box_reg: 0.1966  total_val_loss: 0.4087  val_loss_cls: 0.1533  val_loss_box_reg: 0.2414    time: 1.0408  last_time: 0.9683  data_time: 0.0335  last_data_time: 0.0306   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:58:52 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 4439  total_loss: 0.3355  loss_cls: 0.1501  loss_box_reg: 0.2052  total_val_loss: 0.4277  val_loss_cls: 0.1709  val_loss_box_reg: 0.2607    time: 1.0407  last_time: 0.9693  data_time: 0.0424  last_data_time: 0.0300   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:59:23 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 4459  total_loss: 0.4357  loss_cls: 0.1793  loss_box_reg: 0.2414  total_val_loss: 0.4181  val_loss_cls: 0.1471  val_loss_box_reg: 0.2544    time: 1.0408  last_time: 0.9858  data_time: 0.0306  last_data_time: 0.0554   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 20:59:52 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 4479  total_loss: 0.3979  loss_cls: 0.1656  loss_box_reg: 0.2299  total_val_loss: 0.468  val_loss_cls: 0.1742  val_loss_box_reg: 0.2908    time: 1.0407  last_time: 1.1236  data_time: 0.0287  last_data_time: 0.0347   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:00:24 d2.utils.events]: \u001b[0m eta: 0:25:48  iter: 4499  total_loss: 0.4052  loss_cls: 0.1458  loss_box_reg: 0.2549  total_val_loss: 0.4983  val_loss_cls: 0.1895  val_loss_box_reg: 0.2981    time: 1.0408  last_time: 0.9726  data_time: 0.0440  last_data_time: 0.0370   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:00:54 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 4519  total_loss: 0.33  loss_cls: 0.1338  loss_box_reg: 0.189  total_val_loss: 0.4056  val_loss_cls: 0.1568  val_loss_box_reg: 0.247    time: 1.0409  last_time: 0.8698  data_time: 0.0408  last_data_time: 0.0402   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:01:25 d2.utils.events]: \u001b[0m eta: 0:25:14  iter: 4539  total_loss: 0.3653  loss_cls: 0.1719  loss_box_reg: 0.2091  total_val_loss: 0.4549  val_loss_cls: 0.1724  val_loss_box_reg: 0.2894    time: 1.0410  last_time: 1.0065  data_time: 0.0343  last_data_time: 0.0580   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:01:55 d2.utils.events]: \u001b[0m eta: 0:26:13  iter: 4559  total_loss: 0.3887  loss_cls: 0.1502  loss_box_reg: 0.2213  total_val_loss: 0.449  val_loss_cls: 0.1534  val_loss_box_reg: 0.2739    time: 1.0411  last_time: 0.9268  data_time: 0.0278  last_data_time: 0.0104   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:02:26 d2.utils.events]: \u001b[0m eta: 0:25:53  iter: 4579  total_loss: 0.4498  loss_cls: 0.1689  loss_box_reg: 0.2706  total_val_loss: 0.5039  val_loss_cls: 0.198  val_loss_box_reg: 0.3018    time: 1.0413  last_time: 1.1374  data_time: 0.0342  last_data_time: 0.0356   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:02:56 d2.utils.events]: \u001b[0m eta: 0:25:31  iter: 4599  total_loss: 0.3346  loss_cls: 0.1392  loss_box_reg: 0.1974  total_val_loss: 0.3502  val_loss_cls: 0.1366  val_loss_box_reg: 0.2163    time: 1.0413  last_time: 0.9487  data_time: 0.0324  last_data_time: 0.0125   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:03:26 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 4619  total_loss: 0.2975  loss_cls: 0.1176  loss_box_reg: 0.181  total_val_loss: 0.4302  val_loss_cls: 0.1501  val_loss_box_reg: 0.2762    time: 1.0414  last_time: 1.0999  data_time: 0.0359  last_data_time: 0.0111   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:03:57 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 4639  total_loss: 0.3821  loss_cls: 0.1568  loss_box_reg: 0.2334  total_val_loss: 0.3855  val_loss_cls: 0.1483  val_loss_box_reg: 0.2336    time: 1.0415  last_time: 1.0127  data_time: 0.0346  last_data_time: 0.0568   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:04:27 d2.utils.events]: \u001b[0m eta: 0:24:32  iter: 4659  total_loss: 0.3032  loss_cls: 0.1257  loss_box_reg: 0.1776  total_val_loss: 0.4182  val_loss_cls: 0.171  val_loss_box_reg: 0.2631    time: 1.0415  last_time: 1.1309  data_time: 0.0304  last_data_time: 0.0212   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:04:57 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 4679  total_loss: 0.4261  loss_cls: 0.1749  loss_box_reg: 0.2587  total_val_loss: 0.4463  val_loss_cls: 0.1682  val_loss_box_reg: 0.269    time: 1.0416  last_time: 0.9369  data_time: 0.0349  last_data_time: 0.0325   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:05:28 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 4699  total_loss: 0.373  loss_cls: 0.1522  loss_box_reg: 0.2164  total_val_loss: 0.3966  val_loss_cls: 0.1493  val_loss_box_reg: 0.2431    time: 1.0417  last_time: 1.1147  data_time: 0.0335  last_data_time: 0.0163   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:05:57 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 4719  total_loss: 0.4132  loss_cls: 0.1812  loss_box_reg: 0.2373  total_val_loss: 0.441  val_loss_cls: 0.161  val_loss_box_reg: 0.2824    time: 1.0416  last_time: 0.8702  data_time: 0.0315  last_data_time: 0.0106   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:06:27 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 4739  total_loss: 0.4102  loss_cls: 0.1652  loss_box_reg: 0.2455  total_val_loss: 0.4595  val_loss_cls: 0.1755  val_loss_box_reg: 0.2776    time: 1.0415  last_time: 0.9577  data_time: 0.0259  last_data_time: 0.0342   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:06:57 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 4759  total_loss: 0.3769  loss_cls: 0.1456  loss_box_reg: 0.2354  total_val_loss: 0.4032  val_loss_cls: 0.1592  val_loss_box_reg: 0.2469    time: 1.0416  last_time: 1.1230  data_time: 0.0275  last_data_time: 0.0297   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:07:26 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 4779  total_loss: 0.4015  loss_cls: 0.1633  loss_box_reg: 0.2409  total_val_loss: 0.4733  val_loss_cls: 0.1742  val_loss_box_reg: 0.2999    time: 1.0416  last_time: 0.8856  data_time: 0.0353  last_data_time: 0.0484   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:07:57 d2.utils.events]: \u001b[0m eta: 0:21:58  iter: 4799  total_loss: 0.3647  loss_cls: 0.1485  loss_box_reg: 0.2212  total_val_loss: 0.4399  val_loss_cls: 0.1557  val_loss_box_reg: 0.2881    time: 1.0416  last_time: 1.1675  data_time: 0.0275  last_data_time: 0.0591   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:08:27 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 4819  total_loss: 0.3991  loss_cls: 0.1714  loss_box_reg: 0.2456  total_val_loss: 0.5137  val_loss_cls: 0.1871  val_loss_box_reg: 0.3005    time: 1.0417  last_time: 1.1251  data_time: 0.0344  last_data_time: 0.0120   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:08:57 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 4839  total_loss: 0.3243  loss_cls: 0.1421  loss_box_reg: 0.2007  total_val_loss: 0.4665  val_loss_cls: 0.1805  val_loss_box_reg: 0.2807    time: 1.0418  last_time: 1.1223  data_time: 0.0437  last_data_time: 0.0355   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:09:27 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 4859  total_loss: 0.3371  loss_cls: 0.1352  loss_box_reg: 0.2022  total_val_loss: 0.4917  val_loss_cls: 0.1892  val_loss_box_reg: 0.3024    time: 1.0418  last_time: 0.9729  data_time: 0.0273  last_data_time: 0.0387   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:09:56 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 4879  total_loss: 0.3897  loss_cls: 0.1437  loss_box_reg: 0.2357  total_val_loss: 0.4503  val_loss_cls: 0.1669  val_loss_box_reg: 0.2791    time: 1.0417  last_time: 0.8738  data_time: 0.0371  last_data_time: 0.0294   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:10:26 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 4899  total_loss: 0.357  loss_cls: 0.1413  loss_box_reg: 0.2297  total_val_loss: 0.4227  val_loss_cls: 0.1431  val_loss_box_reg: 0.2736    time: 1.0417  last_time: 1.0980  data_time: 0.0336  last_data_time: 0.0109   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:10:55 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 4919  total_loss: 0.3274  loss_cls: 0.1372  loss_box_reg: 0.1972  total_val_loss: 0.4044  val_loss_cls: 0.1517  val_loss_box_reg: 0.2652    time: 1.0416  last_time: 0.8646  data_time: 0.0310  last_data_time: 0.0329   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:11:25 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 4939  total_loss: 0.3323  loss_cls: 0.133  loss_box_reg: 0.2036  total_val_loss: 0.5447  val_loss_cls: 0.198  val_loss_box_reg: 0.3196    time: 1.0416  last_time: 1.1799  data_time: 0.0295  last_data_time: 0.0556   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:11:55 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 4959  total_loss: 0.3791  loss_cls: 0.1461  loss_box_reg: 0.2395  total_val_loss: 0.4101  val_loss_cls: 0.1579  val_loss_box_reg: 0.2601    time: 1.0417  last_time: 1.1597  data_time: 0.0362  last_data_time: 0.0509   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:12:24 d2.utils.events]: \u001b[0m eta: 0:18:40  iter: 4979  total_loss: 0.394  loss_cls: 0.1554  loss_box_reg: 0.2381  total_val_loss: 0.4167  val_loss_cls: 0.15  val_loss_box_reg: 0.2565    time: 1.0417  last_time: 0.8609  data_time: 0.0335  last_data_time: 0.0247   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:12:56 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 4999  total_loss: 0.3065  loss_cls: 0.1353  loss_box_reg: 0.1617  total_val_loss: 0.4176  val_loss_cls: 0.1645  val_loss_box_reg: 0.2576    time: 1.0417  last_time: 0.9744  data_time: 0.0391  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:13:27 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 5019  total_loss: 0.3174  loss_cls: 0.1222  loss_box_reg: 0.1932  total_val_loss: 0.4488  val_loss_cls: 0.1589  val_loss_box_reg: 0.2979    time: 1.0419  last_time: 1.1030  data_time: 0.0411  last_data_time: 0.0117   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:13:58 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 5039  total_loss: 0.3341  loss_cls: 0.135  loss_box_reg: 0.1843  total_val_loss: 0.5407  val_loss_cls: 0.1996  val_loss_box_reg: 0.3377    time: 1.0421  last_time: 1.1374  data_time: 0.0303  last_data_time: 0.0272   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:14:28 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 5059  total_loss: 0.346  loss_cls: 0.1277  loss_box_reg: 0.2272  total_val_loss: 0.373  val_loss_cls: 0.149  val_loss_box_reg: 0.2327    time: 1.0421  last_time: 1.1503  data_time: 0.0349  last_data_time: 0.0360   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:14:57 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 5079  total_loss: 0.3902  loss_cls: 0.1581  loss_box_reg: 0.2252  total_val_loss: 0.3849  val_loss_cls: 0.1508  val_loss_box_reg: 0.244    time: 1.0419  last_time: 1.1196  data_time: 0.0319  last_data_time: 0.0293   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:15:26 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 5099  total_loss: 0.3577  loss_cls: 0.1485  loss_box_reg: 0.2104  total_val_loss: 0.3973  val_loss_cls: 0.1584  val_loss_box_reg: 0.2452    time: 1.0418  last_time: 0.9813  data_time: 0.0339  last_data_time: 0.0379   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:15:56 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 5119  total_loss: 0.3477  loss_cls: 0.1476  loss_box_reg: 0.1888  total_val_loss: 0.4342  val_loss_cls: 0.1766  val_loss_box_reg: 0.2725    time: 1.0418  last_time: 1.1789  data_time: 0.0347  last_data_time: 0.0675   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:16:26 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 5139  total_loss: 0.401  loss_cls: 0.1493  loss_box_reg: 0.2484  total_val_loss: 0.4783  val_loss_cls: 0.1753  val_loss_box_reg: 0.2878    time: 1.0418  last_time: 0.9548  data_time: 0.0352  last_data_time: 0.0126   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:16:56 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 5159  total_loss: 0.3581  loss_cls: 0.1405  loss_box_reg: 0.2052  total_val_loss: 0.386  val_loss_cls: 0.1452  val_loss_box_reg: 0.2437    time: 1.0418  last_time: 0.9326  data_time: 0.0287  last_data_time: 0.0315   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:17:26 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 5179  total_loss: 0.3238  loss_cls: 0.1313  loss_box_reg: 0.2068  total_val_loss: 0.4661  val_loss_cls: 0.1885  val_loss_box_reg: 0.2935    time: 1.0418  last_time: 1.1645  data_time: 0.0329  last_data_time: 0.0708   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:17:56 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 5199  total_loss: 0.3337  loss_cls: 0.1369  loss_box_reg: 0.2001  total_val_loss: 0.5151  val_loss_cls: 0.1999  val_loss_box_reg: 0.3209    time: 1.0419  last_time: 1.1373  data_time: 0.0356  last_data_time: 0.0221   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:18:27 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 5219  total_loss: 0.3844  loss_cls: 0.1471  loss_box_reg: 0.2385  total_val_loss: 0.4242  val_loss_cls: 0.1552  val_loss_box_reg: 0.2685    time: 1.0420  last_time: 1.1057  data_time: 0.0296  last_data_time: 0.0108   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:18:58 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 5239  total_loss: 0.334  loss_cls: 0.1359  loss_box_reg: 0.2027  total_val_loss: 0.3635  val_loss_cls: 0.136  val_loss_box_reg: 0.2309    time: 1.0421  last_time: 0.9573  data_time: 0.0359  last_data_time: 0.0118   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:19:28 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 5259  total_loss: 0.3791  loss_cls: 0.1527  loss_box_reg: 0.2509  total_val_loss: 0.4308  val_loss_cls: 0.16  val_loss_box_reg: 0.2707    time: 1.0423  last_time: 1.1058  data_time: 0.0338  last_data_time: 0.0135   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:19:58 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 5279  total_loss: 0.3292  loss_cls: 0.1285  loss_box_reg: 0.2012  total_val_loss: 0.4549  val_loss_cls: 0.1532  val_loss_box_reg: 0.2951    time: 1.0423  last_time: 1.1659  data_time: 0.0342  last_data_time: 0.0493   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:20:29 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 5299  total_loss: 0.3625  loss_cls: 0.1407  loss_box_reg: 0.2203  total_val_loss: 0.4969  val_loss_cls: 0.1785  val_loss_box_reg: 0.3063    time: 1.0424  last_time: 0.9807  data_time: 0.0355  last_data_time: 0.0209   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:20:58 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 5319  total_loss: 0.3754  loss_cls: 0.1567  loss_box_reg: 0.21  total_val_loss: 0.4149  val_loss_cls: 0.1593  val_loss_box_reg: 0.2642    time: 1.0423  last_time: 0.9732  data_time: 0.0319  last_data_time: 0.0341   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:21:29 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 5339  total_loss: 0.345  loss_cls: 0.1507  loss_box_reg: 0.2107  total_val_loss: 0.4358  val_loss_cls: 0.1653  val_loss_box_reg: 0.2694    time: 1.0425  last_time: 1.1276  data_time: 0.0428  last_data_time: 0.0343   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:21:59 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 5359  total_loss: 0.3956  loss_cls: 0.1529  loss_box_reg: 0.2373  total_val_loss: 0.4168  val_loss_cls: 0.1632  val_loss_box_reg: 0.2665    time: 1.0424  last_time: 1.1690  data_time: 0.0327  last_data_time: 0.0579   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:22:29 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 5379  total_loss: 0.3751  loss_cls: 0.1509  loss_box_reg: 0.2232  total_val_loss: 0.4194  val_loss_cls: 0.1641  val_loss_box_reg: 0.2556    time: 1.0424  last_time: 0.9357  data_time: 0.0259  last_data_time: 0.0146   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:22:59 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 5399  total_loss: 0.3619  loss_cls: 0.137  loss_box_reg: 0.2248  total_val_loss: 0.4647  val_loss_cls: 0.187  val_loss_box_reg: 0.2798    time: 1.0425  last_time: 0.9166  data_time: 0.0370  last_data_time: 0.0171   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:23:29 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 5419  total_loss: 0.3347  loss_cls: 0.1551  loss_box_reg: 0.2051  total_val_loss: 0.4223  val_loss_cls: 0.164  val_loss_box_reg: 0.2654    time: 1.0425  last_time: 0.9817  data_time: 0.0371  last_data_time: 0.0357   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:23:59 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 5439  total_loss: 0.3858  loss_cls: 0.1536  loss_box_reg: 0.2395  total_val_loss: 0.3859  val_loss_cls: 0.1428  val_loss_box_reg: 0.2383    time: 1.0426  last_time: 1.0223  data_time: 0.0376  last_data_time: 0.0647   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:24:29 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 5459  total_loss: 0.3699  loss_cls: 0.1463  loss_box_reg: 0.2151  total_val_loss: 0.4365  val_loss_cls: 0.17  val_loss_box_reg: 0.2546    time: 1.0425  last_time: 1.1363  data_time: 0.0287  last_data_time: 0.0320   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:24:59 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 5479  total_loss: 0.4204  loss_cls: 0.1626  loss_box_reg: 0.2594  total_val_loss: 0.372  val_loss_cls: 0.1568  val_loss_box_reg: 0.2502    time: 1.0426  last_time: 1.1219  data_time: 0.0300  last_data_time: 0.0332   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:25:30 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 5499  total_loss: 0.3257  loss_cls: 0.1426  loss_box_reg: 0.1737  total_val_loss: 0.4311  val_loss_cls: 0.1783  val_loss_box_reg: 0.2702    time: 1.0427  last_time: 0.9770  data_time: 0.0375  last_data_time: 0.0343   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:26:00 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 5519  total_loss: 0.335  loss_cls: 0.1256  loss_box_reg: 0.1978  total_val_loss: 0.4484  val_loss_cls: 0.1783  val_loss_box_reg: 0.2737    time: 1.0426  last_time: 0.9814  data_time: 0.0318  last_data_time: 0.0094   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:26:30 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 5539  total_loss: 0.3336  loss_cls: 0.142  loss_box_reg: 0.2071  total_val_loss: 0.4046  val_loss_cls: 0.1593  val_loss_box_reg: 0.2491    time: 1.0426  last_time: 1.1172  data_time: 0.0282  last_data_time: 0.0101   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:27:00 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 5559  total_loss: 0.3793  loss_cls: 0.1491  loss_box_reg: 0.229  total_val_loss: 0.4774  val_loss_cls: 0.1728  val_loss_box_reg: 0.3021    time: 1.0425  last_time: 0.9575  data_time: 0.0328  last_data_time: 0.0163   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:27:31 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 5579  total_loss: 0.3674  loss_cls: 0.1607  loss_box_reg: 0.2036  total_val_loss: 0.4433  val_loss_cls: 0.1625  val_loss_box_reg: 0.2761    time: 1.0427  last_time: 1.1290  data_time: 0.0358  last_data_time: 0.0347   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:28:01 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 5599  total_loss: 0.3774  loss_cls: 0.1383  loss_box_reg: 0.2393  total_val_loss: 0.4427  val_loss_cls: 0.1646  val_loss_box_reg: 0.2714    time: 1.0427  last_time: 0.9404  data_time: 0.0374  last_data_time: 0.0323   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:28:31 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 5619  total_loss: 0.2946  loss_cls: 0.1412  loss_box_reg: 0.1805  total_val_loss: 0.4424  val_loss_cls: 0.1761  val_loss_box_reg: 0.2706    time: 1.0427  last_time: 1.1196  data_time: 0.0314  last_data_time: 0.0096   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:29:00 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 5639  total_loss: 0.3939  loss_cls: 0.1548  loss_box_reg: 0.2229  total_val_loss: 0.3608  val_loss_cls: 0.1235  val_loss_box_reg: 0.2373    time: 1.0426  last_time: 0.9743  data_time: 0.0337  last_data_time: 0.0322   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:29:30 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 5659  total_loss: 0.3677  loss_cls: 0.1467  loss_box_reg: 0.2231  total_val_loss: 0.4049  val_loss_cls: 0.1696  val_loss_box_reg: 0.2357    time: 1.0427  last_time: 1.1212  data_time: 0.0449  last_data_time: 0.0271   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:30:01 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 5679  total_loss: 0.2853  loss_cls: 0.1193  loss_box_reg: 0.1689  total_val_loss: 0.4932  val_loss_cls: 0.1793  val_loss_box_reg: 0.305    time: 1.0428  last_time: 1.1252  data_time: 0.0339  last_data_time: 0.0317   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:30:31 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 5699  total_loss: 0.3849  loss_cls: 0.1446  loss_box_reg: 0.2335  total_val_loss: 0.4224  val_loss_cls: 0.1535  val_loss_box_reg: 0.2498    time: 1.0429  last_time: 1.0168  data_time: 0.0296  last_data_time: 0.0561   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:31:02 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 5719  total_loss: 0.3884  loss_cls: 0.16  loss_box_reg: 0.2288  total_val_loss: 0.468  val_loss_cls: 0.1845  val_loss_box_reg: 0.2831    time: 1.0429  last_time: 1.1189  data_time: 0.0284  last_data_time: 0.0105   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:31:32 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 5739  total_loss: 0.3622  loss_cls: 0.1505  loss_box_reg: 0.2188  total_val_loss: 0.4415  val_loss_cls: 0.1685  val_loss_box_reg: 0.269    time: 1.0430  last_time: 0.9775  data_time: 0.0389  last_data_time: 0.0372   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:32:02 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 5759  total_loss: 0.3467  loss_cls: 0.1356  loss_box_reg: 0.2112  total_val_loss: 0.4933  val_loss_cls: 0.1788  val_loss_box_reg: 0.3155    time: 1.0430  last_time: 1.1341  data_time: 0.0352  last_data_time: 0.0356   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:32:34 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 5779  total_loss: 0.3869  loss_cls: 0.1398  loss_box_reg: 0.2345  total_val_loss: 0.4428  val_loss_cls: 0.1776  val_loss_box_reg: 0.2668    time: 1.0432  last_time: 0.9936  data_time: 0.0408  last_data_time: 0.0411   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:33:04 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 5799  total_loss: 0.3763  loss_cls: 0.1403  loss_box_reg: 0.2494  total_val_loss: 0.4103  val_loss_cls: 0.1561  val_loss_box_reg: 0.26    time: 1.0433  last_time: 1.0347  data_time: 0.0312  last_data_time: 0.0691   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:33:34 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 5819  total_loss: 0.3827  loss_cls: 0.1609  loss_box_reg: 0.2039  total_val_loss: 0.3777  val_loss_cls: 0.1405  val_loss_box_reg: 0.2417    time: 1.0433  last_time: 1.1115  data_time: 0.0327  last_data_time: 0.0136   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:34:04 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 5839  total_loss: 0.3168  loss_cls: 0.1487  loss_box_reg: 0.1863  total_val_loss: 0.4502  val_loss_cls: 0.1729  val_loss_box_reg: 0.2718    time: 1.0432  last_time: 1.1076  data_time: 0.0332  last_data_time: 0.0127   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:34:34 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 5859  total_loss: 0.3533  loss_cls: 0.144  loss_box_reg: 0.2101  total_val_loss: 0.4959  val_loss_cls: 0.1803  val_loss_box_reg: 0.3078    time: 1.0432  last_time: 0.9467  data_time: 0.0328  last_data_time: 0.0334   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:35:02 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 5879  total_loss: 0.3414  loss_cls: 0.1302  loss_box_reg: 0.2062  total_val_loss: 0.4016  val_loss_cls: 0.1573  val_loss_box_reg: 0.2443    time: 1.0431  last_time: 1.0243  data_time: 0.0351  last_data_time: 0.0616   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:35:33 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 5899  total_loss: 0.347  loss_cls: 0.1274  loss_box_reg: 0.2069  total_val_loss: 0.4446  val_loss_cls: 0.1598  val_loss_box_reg: 0.2782    time: 1.0431  last_time: 0.9385  data_time: 0.0358  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:36:03 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 5919  total_loss: 0.4208  loss_cls: 0.1662  loss_box_reg: 0.2594  total_val_loss: 0.4314  val_loss_cls: 0.1498  val_loss_box_reg: 0.2783    time: 1.0431  last_time: 0.9212  data_time: 0.0317  last_data_time: 0.0169   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:36:32 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 5939  total_loss: 0.341  loss_cls: 0.1527  loss_box_reg: 0.1976  total_val_loss: 0.4482  val_loss_cls: 0.1637  val_loss_box_reg: 0.2792    time: 1.0430  last_time: 1.1766  data_time: 0.0351  last_data_time: 0.0639   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:37:03 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 5959  total_loss: 0.4135  loss_cls: 0.1662  loss_box_reg: 0.2425  total_val_loss: 0.4333  val_loss_cls: 0.1485  val_loss_box_reg: 0.2954    time: 1.0431  last_time: 1.1818  data_time: 0.0307  last_data_time: 0.0661   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:37:33 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 5979  total_loss: 0.3862  loss_cls: 0.1663  loss_box_reg: 0.2138  total_val_loss: 0.4417  val_loss_cls: 0.1622  val_loss_box_reg: 0.2832    time: 1.0432  last_time: 0.9396  data_time: 0.0318  last_data_time: 0.0339   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:38:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 5999  total_loss: 0.3406  loss_cls: 0.129  loss_box_reg: 0.2102  total_val_loss: 0.4702  val_loss_cls: 0.1855  val_loss_box_reg: 0.2847    time: 1.0432  last_time: 1.1201  data_time: 0.0439  last_data_time: 0.0312   lr: 1e-05  max_mem: 5545M\n",
            "\u001b[32m[12/12 21:38:06 d2.engine.hooks]: \u001b[0mOverall training speed: 5998 iterations in 1:44:16 (1.0432 s / it)\n",
            "\u001b[32m[12/12 21:38:06 d2.engine.hooks]: \u001b[0mTotal training time: 2:30:10 (0:45:53 on hooks)\n"
          ]
        }
      ]
    }
  ]
}